{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52fb9015-0bf4-4d29-8834-482a8e4ad084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wooldridge as wd\n",
    "from arch import arch_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from pmdarima import auto_arima\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import chi2\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a709ccb-2f5e-457d-9740-f8044bec45c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>i3</th>\n",
       "      <th>inf</th>\n",
       "      <th>rec</th>\n",
       "      <th>out</th>\n",
       "      <th>def</th>\n",
       "      <th>i3_1</th>\n",
       "      <th>inf_1</th>\n",
       "      <th>def_1</th>\n",
       "      <th>ci3</th>\n",
       "      <th>cinf</th>\n",
       "      <th>cdef</th>\n",
       "      <th>y77</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1948</td>\n",
       "      <td>1.04</td>\n",
       "      <td>8.1</td>\n",
       "      <td>16.200001</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>-4.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949</td>\n",
       "      <td>1.10</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>14.300000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>1.04</td>\n",
       "      <td>8.1</td>\n",
       "      <td>-4.600000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>-9.3</td>\n",
       "      <td>4.400001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1950</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.3</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>1.200001</td>\n",
       "      <td>1.10</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.400001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1951</td>\n",
       "      <td>1.55</td>\n",
       "      <td>7.9</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>-1.900001</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.200001</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>6.6</td>\n",
       "      <td>-3.100001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1952</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.9</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.55</td>\n",
       "      <td>7.9</td>\n",
       "      <td>-1.900001</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1953</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.8</td>\n",
       "      <td>18.700001</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>1.699999</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1.299999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1954</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.7</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>18.799999</td>\n",
       "      <td>0.299999</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.699999</td>\n",
       "      <td>-0.980000</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.400000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1955</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>0.799999</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.299999</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1956</td>\n",
       "      <td>2.66</td>\n",
       "      <td>1.5</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.799999</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-1.799999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1957</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.3</td>\n",
       "      <td>17.700001</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>-0.700001</td>\n",
       "      <td>2.66</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.299999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1958</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2.8</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.3</td>\n",
       "      <td>-0.700001</td>\n",
       "      <td>-1.430000</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.300001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1959</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.7</td>\n",
       "      <td>16.200001</td>\n",
       "      <td>18.799999</td>\n",
       "      <td>2.599998</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.570000</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>1.999998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1960</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1.7</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.599998</td>\n",
       "      <td>-0.480000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.599998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1961</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1962</td>\n",
       "      <td>2.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>18.799999</td>\n",
       "      <td>1.199999</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.599998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1963</td>\n",
       "      <td>3.16</td>\n",
       "      <td>1.3</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>0.800001</td>\n",
       "      <td>2.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.199999</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.399998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1964</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.3</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>3.16</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.800001</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1965</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1.6</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.200001</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.699999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1966</td>\n",
       "      <td>4.88</td>\n",
       "      <td>2.9</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.200001</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.299999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1967</td>\n",
       "      <td>4.32</td>\n",
       "      <td>3.1</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.88</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.560000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1968</td>\n",
       "      <td>5.34</td>\n",
       "      <td>4.2</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>4.32</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1969</td>\n",
       "      <td>6.68</td>\n",
       "      <td>5.5</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>-0.300001</td>\n",
       "      <td>5.34</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.340000</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-3.200001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1970</td>\n",
       "      <td>6.46</td>\n",
       "      <td>5.7</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.299999</td>\n",
       "      <td>0.299999</td>\n",
       "      <td>6.68</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-0.300001</td>\n",
       "      <td>-0.220000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1971</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.4</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>2.200001</td>\n",
       "      <td>6.46</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.299999</td>\n",
       "      <td>-2.110000</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>1.900002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1972</td>\n",
       "      <td>4.07</td>\n",
       "      <td>3.2</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.200001</td>\n",
       "      <td>-0.280000</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-0.200001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1973</td>\n",
       "      <td>7.04</td>\n",
       "      <td>6.2</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>18.700001</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>4.07</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.970000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1974</td>\n",
       "      <td>7.89</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.299999</td>\n",
       "      <td>18.700001</td>\n",
       "      <td>0.400002</td>\n",
       "      <td>7.04</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>4.8</td>\n",
       "      <td>-0.699999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1975</td>\n",
       "      <td>5.84</td>\n",
       "      <td>9.1</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>21.299999</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>7.89</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.400002</td>\n",
       "      <td>-2.050000</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>2.999998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1976</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.8</td>\n",
       "      <td>17.100000</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>4.299999</td>\n",
       "      <td>5.84</td>\n",
       "      <td>9.1</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>-0.850000</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1977</td>\n",
       "      <td>5.27</td>\n",
       "      <td>6.5</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.700001</td>\n",
       "      <td>2.700001</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.299999</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-1.599998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1978</td>\n",
       "      <td>7.22</td>\n",
       "      <td>7.6</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.700001</td>\n",
       "      <td>2.700001</td>\n",
       "      <td>5.27</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.700001</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1979</td>\n",
       "      <td>10.04</td>\n",
       "      <td>11.3</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>20.100000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>7.22</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.700001</td>\n",
       "      <td>2.820000</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1980</td>\n",
       "      <td>11.51</td>\n",
       "      <td>13.5</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>2.700001</td>\n",
       "      <td>10.04</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1981</td>\n",
       "      <td>14.03</td>\n",
       "      <td>10.3</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>22.200001</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>11.51</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2.700001</td>\n",
       "      <td>2.520000</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1982</td>\n",
       "      <td>10.69</td>\n",
       "      <td>6.2</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>14.03</td>\n",
       "      <td>10.3</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>-3.340000</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>1.299999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1983</td>\n",
       "      <td>8.63</td>\n",
       "      <td>3.2</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>10.69</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>-2.059999</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2.200001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1984</td>\n",
       "      <td>9.58</td>\n",
       "      <td>4.3</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>22.100000</td>\n",
       "      <td>4.800001</td>\n",
       "      <td>8.63</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-1.299999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1985</td>\n",
       "      <td>7.48</td>\n",
       "      <td>3.6</td>\n",
       "      <td>17.700001</td>\n",
       "      <td>22.799999</td>\n",
       "      <td>5.099998</td>\n",
       "      <td>9.58</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.800001</td>\n",
       "      <td>-2.100000</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.299997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1986</td>\n",
       "      <td>5.98</td>\n",
       "      <td>1.9</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.48</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.099998</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-0.099998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1987</td>\n",
       "      <td>5.82</td>\n",
       "      <td>3.6</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>3.200001</td>\n",
       "      <td>5.98</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-1.799999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1988</td>\n",
       "      <td>6.69</td>\n",
       "      <td>4.1</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>21.200001</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>5.82</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.200001</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1989</td>\n",
       "      <td>8.12</td>\n",
       "      <td>4.8</td>\n",
       "      <td>18.299999</td>\n",
       "      <td>21.200001</td>\n",
       "      <td>2.900002</td>\n",
       "      <td>6.69</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.199999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1990</td>\n",
       "      <td>7.51</td>\n",
       "      <td>5.4</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>21.799999</td>\n",
       "      <td>3.799999</td>\n",
       "      <td>8.12</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.900002</td>\n",
       "      <td>-0.610000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.899998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1991</td>\n",
       "      <td>5.42</td>\n",
       "      <td>4.2</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>22.299999</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>7.51</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.799999</td>\n",
       "      <td>-2.090000</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>0.700001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1992</td>\n",
       "      <td>3.45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>22.100000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>5.42</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>-1.970000</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1993</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>-0.430000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.700001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1994</td>\n",
       "      <td>4.29</td>\n",
       "      <td>2.6</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1995</td>\n",
       "      <td>5.51</td>\n",
       "      <td>2.8</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>20.700001</td>\n",
       "      <td>2.200001</td>\n",
       "      <td>4.29</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.220000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.699999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1996</td>\n",
       "      <td>5.02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>20.299999</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>5.51</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.200001</td>\n",
       "      <td>-0.490000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.800001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1997</td>\n",
       "      <td>5.07</td>\n",
       "      <td>2.3</td>\n",
       "      <td>19.299999</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>0.300001</td>\n",
       "      <td>5.02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-1.099998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1998</td>\n",
       "      <td>4.81</td>\n",
       "      <td>1.6</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>-0.799999</td>\n",
       "      <td>5.07</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.300001</td>\n",
       "      <td>-0.260000</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1999</td>\n",
       "      <td>4.66</td>\n",
       "      <td>2.2</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>-1.400000</td>\n",
       "      <td>4.81</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-0.799999</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2000</td>\n",
       "      <td>5.85</td>\n",
       "      <td>3.4</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>4.66</td>\n",
       "      <td>2.2</td>\n",
       "      <td>-1.400000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2001</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.8</td>\n",
       "      <td>19.799999</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>-1.199999</td>\n",
       "      <td>5.85</td>\n",
       "      <td>3.4</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>-2.400000</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1.300001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2002</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.6</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-1.199999</td>\n",
       "      <td>-1.830000</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>2.699999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2003</td>\n",
       "      <td>1.02</td>\n",
       "      <td>2.3</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year     i3   inf        rec        out       def   i3_1  inf_1     def_1  \\\n",
       "0   1948   1.04   8.1  16.200001  11.600000 -4.600000    NaN    NaN       NaN   \n",
       "1   1949   1.10  -1.2  14.500000  14.300000 -0.200000   1.04    8.1 -4.600000   \n",
       "2   1950   1.22   1.3  14.400000  15.600000  1.200001   1.10   -1.2 -0.200000   \n",
       "3   1951   1.55   7.9  16.100000  14.200000 -1.900001   1.22    1.3  1.200001   \n",
       "4   1952   1.77   1.9  19.000000  19.400000  0.400000   1.55    7.9 -1.900001   \n",
       "5   1953   1.93   0.8  18.700001  20.400000  1.699999   1.77    1.9  0.400000   \n",
       "6   1954   0.95   0.7  18.500000  18.799999  0.299999   1.93    0.8  1.699999   \n",
       "7   1955   1.75  -0.4  16.500000  17.299999  0.799999   0.95    0.7  0.299999   \n",
       "8   1956   2.66   1.5  17.500000  16.500000 -1.000000   1.75   -0.4  0.799999   \n",
       "9   1957   3.27   3.3  17.700001  17.000000 -0.700001   2.66    1.5 -1.000000   \n",
       "10  1958   1.84   2.8  17.299999  17.900000  0.600000   3.27    3.3 -0.700001   \n",
       "11  1959   3.41   0.7  16.200001  18.799999  2.599998   1.84    2.8  0.600000   \n",
       "12  1960   2.93   1.7  17.799999  17.799999  0.000000   3.41    0.7  2.599998   \n",
       "13  1961   2.38   1.0  17.799999  18.400000  0.600000   2.93    1.7  0.000000   \n",
       "14  1962   2.78   1.0  17.600000  18.799999  1.199999   2.38    1.0  0.600000   \n",
       "15  1963   3.16   1.3  17.799999  18.600000  0.800001   2.78    1.0  1.199999   \n",
       "16  1964   3.55   1.3  17.600000  18.500000  0.900000   3.16    1.3  0.800001   \n",
       "17  1965   3.95   1.6  17.000000  17.200001  0.200001   3.55    1.3  0.900000   \n",
       "18  1966   4.88   2.9  17.299999  17.799999  0.500000   3.95    1.6  0.200001   \n",
       "19  1967   4.32   3.1  18.400000  19.400000  1.000000   4.88    2.9  0.500000   \n",
       "20  1968   5.34   4.2  17.600000  20.500000  2.900000   4.32    3.1  1.000000   \n",
       "21  1969   6.68   5.5  19.700001  19.400000 -0.300001   5.34    4.2  2.900000   \n",
       "22  1970   6.46   5.7  19.000000  19.299999  0.299999   6.68    5.5 -0.300001   \n",
       "23  1971   4.35   4.4  17.299999  19.500000  2.200001   6.46    5.7  0.299999   \n",
       "24  1972   4.07   3.2  17.600000  19.600000  2.000000   4.35    4.4  2.200001   \n",
       "25  1973   7.04   6.2  17.600000  18.700001  1.100000   4.07    3.2  2.000000   \n",
       "26  1974   7.89  11.0  18.299999  18.700001  0.400002   7.04    6.2  1.100000   \n",
       "27  1975   5.84   9.1  17.900000  21.299999  3.400000   7.89   11.0  0.400002   \n",
       "28  1976   4.99   5.8  17.100000  21.400000  4.299999   5.84    9.1  3.400000   \n",
       "29  1977   5.27   6.5  18.000000  20.700001  2.700001   4.99    5.8  4.299999   \n",
       "30  1978   7.22   7.6  18.000000  20.700001  2.700001   5.27    6.5  2.700001   \n",
       "31  1979  10.04  11.3  18.500000  20.100000  1.600000   7.22    7.6  2.700001   \n",
       "32  1980  11.51  13.5  19.000000  21.700001  2.700001  10.04   11.3  1.600000   \n",
       "33  1981  14.03  10.3  19.600000  22.200001  2.600000  11.51   13.5  2.700001   \n",
       "34  1982  10.69   6.2  19.200001  23.100000  3.900000  14.03   10.3  2.600000   \n",
       "35  1983   8.63   3.2  17.400000  23.500000  6.100000  10.69    6.2  3.900000   \n",
       "36  1984   9.58   4.3  17.299999  22.100000  4.800001   8.63    3.2  6.100000   \n",
       "37  1985   7.48   3.6  17.700001  22.799999  5.099998   9.58    4.3  4.800001   \n",
       "38  1986   5.98   1.9  17.500000  22.500000  5.000000   7.48    3.6  5.099998   \n",
       "39  1987   5.82   3.6  18.400000  21.600000  3.200001   5.98    1.9  5.000000   \n",
       "40  1988   6.69   4.1  18.100000  21.200001  3.100000   5.82    3.6  3.200001   \n",
       "41  1989   8.12   4.8  18.299999  21.200001  2.900002   6.69    4.1  3.100000   \n",
       "42  1990   7.51   5.4  18.000000  21.799999  3.799999   8.12    4.8  2.900002   \n",
       "43  1991   5.42   4.2  17.799999  22.299999  4.500000   7.51    5.4  3.799999   \n",
       "44  1992   3.45   3.0  17.500000  22.100000  4.600000   5.42    4.2  4.500000   \n",
       "45  1993   3.02   3.0  17.500000  21.400000  3.900000   3.45    3.0  4.600000   \n",
       "46  1994   4.29   2.6  18.100000  21.000000  2.900000   3.02    3.0  3.900000   \n",
       "47  1995   5.51   2.8  18.500000  20.700001  2.200001   4.29    2.6  2.900000   \n",
       "48  1996   5.02   3.0  18.900000  20.299999  1.400000   5.51    2.8  2.200001   \n",
       "49  1997   5.07   2.3  19.299999  19.600000  0.300001   5.02    3.0  1.400000   \n",
       "50  1998   4.81   1.6  20.000000  19.200001 -0.799999   5.07    2.3  0.300001   \n",
       "51  1999   4.66   2.2  20.000000  18.600000 -1.400000   4.81    1.6 -0.799999   \n",
       "52  2000   5.85   3.4  20.900000  18.400000 -2.500000   4.66    2.2 -1.400000   \n",
       "53  2001   3.45   2.8  19.799999  18.600000 -1.199999   5.85    3.4 -2.500000   \n",
       "54  2002   1.62   1.6  17.900000  19.400000  1.500000   3.45    2.8 -1.199999   \n",
       "55  2003   1.02   2.3  16.500000  19.900000  3.400000   1.62    1.6  1.500000   \n",
       "\n",
       "         ci3  cinf      cdef  y77  \n",
       "0        NaN   NaN       NaN    0  \n",
       "1   0.060000  -9.3  4.400001    0  \n",
       "2   0.120000   2.5  1.400001    0  \n",
       "3   0.330000   6.6 -3.100001    0  \n",
       "4   0.220000  -6.0  2.300000    0  \n",
       "5   0.160000  -1.1  1.299999    0  \n",
       "6  -0.980000  -0.1 -1.400000    0  \n",
       "7   0.800000  -1.1  0.500000    0  \n",
       "8   0.910000   1.9 -1.799999    0  \n",
       "9   0.610000   1.8  0.299999    0  \n",
       "10 -1.430000  -0.5  1.300001    0  \n",
       "11  1.570000  -2.1  1.999998    0  \n",
       "12 -0.480000   1.0 -2.599998    0  \n",
       "13 -0.550000  -0.7  0.600000    0  \n",
       "14  0.400000   0.0  0.599998    0  \n",
       "15  0.380000   0.3 -0.399998    0  \n",
       "16  0.390000   0.0  0.099998    0  \n",
       "17  0.400000   0.3 -0.699999    0  \n",
       "18  0.930000   1.3  0.299999    0  \n",
       "19 -0.560000   0.2  0.500000    0  \n",
       "20  1.020000   1.1  1.900000    0  \n",
       "21  1.340000   1.3 -3.200001    0  \n",
       "22 -0.220000   0.2  0.600000    0  \n",
       "23 -2.110000  -1.3  1.900002    0  \n",
       "24 -0.280000  -1.2 -0.200001    0  \n",
       "25  2.970000   3.0 -0.900000    0  \n",
       "26  0.850000   4.8 -0.699999    0  \n",
       "27 -2.050000  -1.9  2.999998    0  \n",
       "28 -0.850000  -3.3  0.900000    0  \n",
       "29  0.280000   0.7 -1.599998    1  \n",
       "30  1.950000   1.1  0.000000    1  \n",
       "31  2.820000   3.7 -1.100000    1  \n",
       "32  1.470000   2.2  1.100000    1  \n",
       "33  2.520000  -3.2 -0.100000    1  \n",
       "34 -3.340000  -4.1  1.299999    1  \n",
       "35 -2.059999  -3.0  2.200001    1  \n",
       "36  0.950000   1.1 -1.299999    1  \n",
       "37 -2.100000  -0.7  0.299997    1  \n",
       "38 -1.500000  -1.7 -0.099998    1  \n",
       "39 -0.160000   1.7 -1.799999    1  \n",
       "40  0.870000   0.5 -0.100000    1  \n",
       "41  1.430000   0.7 -0.199999    1  \n",
       "42 -0.610000   0.6  0.899998    1  \n",
       "43 -2.090000  -1.2  0.700001    1  \n",
       "44 -1.970000  -1.2  0.100000    1  \n",
       "45 -0.430000   0.0 -0.700001    1  \n",
       "46  1.270000  -0.4 -1.000000    1  \n",
       "47  1.220000   0.2 -0.699999    1  \n",
       "48 -0.490000   0.2 -0.800001    1  \n",
       "49  0.050000  -0.7 -1.099998    1  \n",
       "50 -0.260000  -0.7 -1.100000    1  \n",
       "51 -0.150000   0.6 -0.600000    1  \n",
       "52  1.190000   1.2 -1.100000    1  \n",
       "53 -2.400000  -0.6  1.300001    1  \n",
       "54 -1.830000  -1.2  2.699999    1  \n",
       "55 -0.600000   0.7  1.900000    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Load data\n",
    "intdef = wd.data('intdef')\n",
    "intdef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6775ad6-95d4-4327-a754-60a0af866ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: 130.94000277361826\n",
      "Iteration:      2,   Func. Count:     10,   Neg. LLF: 122.3727197228805\n",
      "Iteration:      3,   Func. Count:     15,   Neg. LLF: 122.2557419760497\n",
      "Iteration:      4,   Func. Count:     20,   Neg. LLF: 122.21513193816268\n",
      "Iteration:      5,   Func. Count:     24,   Neg. LLF: 122.21374982177375\n",
      "Iteration:      6,   Func. Count:     28,   Neg. LLF: 122.21371033849957\n",
      "Iteration:      7,   Func. Count:     32,   Neg. LLF: 122.21370911352173\n",
      "Iteration:      8,   Func. Count:     35,   Neg. LLF: 122.21370911651348\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 122.21370911352173\n",
      "            Iterations: 8\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 8\n",
      "                      Constant Mean - ARCH Model Results                      \n",
      "==============================================================================\n",
      "Dep. Variable:                     i3   R-squared:                       0.000\n",
      "Mean Model:             Constant Mean   Adj. R-squared:                  0.000\n",
      "Vol Model:                       ARCH   Log-Likelihood:               -122.214\n",
      "Distribution:                  Normal   AIC:                           250.427\n",
      "Method:            Maximum Likelihood   BIC:                           256.503\n",
      "                                        No. Observations:                   56\n",
      "Date:                Tue, Jun 10 2025   Df Residuals:                       55\n",
      "Time:                        16:43:10   Df Model:                            1\n",
      "                               Mean Model                               \n",
      "========================================================================\n",
      "                 coef    std err          t      P>|t|  95.0% Conf. Int.\n",
      "------------------------------------------------------------------------\n",
      "mu             4.8449      0.222     21.805 2.089e-105 [  4.409,  5.280]\n",
      "                              Volatility Model                             \n",
      "===========================================================================\n",
      "                 coef    std err          t      P>|t|     95.0% Conf. Int.\n",
      "---------------------------------------------------------------------------\n",
      "omega          0.9420      0.511      1.843  6.528e-02 [-5.959e-02,  1.944]\n",
      "alpha[1]       1.0000      0.225      4.439  9.040e-06    [  0.558,  1.442]\n",
      "===========================================================================\n",
      "\n",
      "Covariance estimator: robust\n"
     ]
    }
   ],
   "source": [
    "##ARCH(1) model\n",
    "model = arch_model(intdef['i3'], vol='ARCH', p=1)\n",
    "res = model.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cee0d3ee-3ca8-4b24-b39c-2be8f3c9d0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      6,   Neg. LLF: 136.1395826789892\n",
      "Iteration:      2,   Func. Count:     12,   Neg. LLF: 7553.465259229088\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: 136.70557296383623\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: 124.33691392297254\n",
      "Iteration:      5,   Func. Count:     30,   Neg. LLF: 122.3830408453359\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: 122.71164259681655\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: 122.22550402835286\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: 122.21385830757879\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: 122.21370995923758\n",
      "Iteration:     10,   Func. Count:     56,   Neg. LLF: 122.21370888353024\n",
      "Iteration:     11,   Func. Count:     60,   Neg. LLF: 122.21370898528826\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 122.21370888353024\n",
      "            Iterations: 11\n",
      "            Function evaluations: 60\n",
      "            Gradient evaluations: 11\n",
      "                     Constant Mean - GARCH Model Results                      \n",
      "==============================================================================\n",
      "Dep. Variable:                     i3   R-squared:                       0.000\n",
      "Mean Model:             Constant Mean   Adj. R-squared:                  0.000\n",
      "Vol Model:                      GARCH   Log-Likelihood:               -122.214\n",
      "Distribution:                  Normal   AIC:                           252.427\n",
      "Method:            Maximum Likelihood   BIC:                           260.529\n",
      "                                        No. Observations:                   56\n",
      "Date:                Tue, Jun 10 2025   Df Residuals:                       55\n",
      "Time:                        16:43:10   Df Model:                            1\n",
      "                               Mean Model                               \n",
      "========================================================================\n",
      "                 coef    std err          t      P>|t|  95.0% Conf. Int.\n",
      "------------------------------------------------------------------------\n",
      "mu             4.8451      0.242     20.000  5.453e-89 [  4.370,  5.320]\n",
      "                              Volatility Model                             \n",
      "===========================================================================\n",
      "                 coef    std err          t      P>|t|     95.0% Conf. Int.\n",
      "---------------------------------------------------------------------------\n",
      "omega          0.9421      0.503      1.874  6.091e-02 [-4.314e-02,  1.927]\n",
      "alpha[1]       1.0000      0.328      3.045  2.329e-03    [  0.356,  1.644]\n",
      "beta[1]    1.8607e-14      0.154  1.212e-13      1.000    [ -0.301,  0.301]\n",
      "===========================================================================\n",
      "\n",
      "Covariance estimator: robust\n"
     ]
    }
   ],
   "source": [
    "#GARCH(1,1) model\n",
    "model = arch_model(intdef['i3'], vol='GARCH', p=1, q=1)\n",
    "res = model.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd0dd72-450a-4761-8ac7-4429d2d10fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Correlogram\n",
    "# GARCH model: conditional variance of the disturbances of the yt sequence constitutes an ARMA process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbad1ae4-cf9a-43a3-9ec3-81b4d0362ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(0,0,0)(0,0,0)[0]             : AIC=355.300, Time=0.02 sec\n",
      " ARIMA(1,0,0)(0,0,0)[0]             : AIC=197.884, Time=0.02 sec\n",
      " ARIMA(0,0,1)(0,0,0)[0]             : AIC=289.476, Time=0.02 sec\n",
      " ARIMA(2,0,0)(0,0,0)[0]             : AIC=197.077, Time=0.02 sec\n",
      " ARIMA(3,0,0)(0,0,0)[0]             : AIC=194.104, Time=0.03 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(4,0,0)(0,0,0)[0]             : AIC=195.917, Time=0.04 sec\n",
      " ARIMA(3,0,1)(0,0,0)[0]             : AIC=195.646, Time=0.05 sec\n",
      " ARIMA(2,0,1)(0,0,0)[0]             : AIC=195.226, Time=0.05 sec\n",
      " ARIMA(4,0,1)(0,0,0)[0]             : AIC=197.364, Time=0.10 sec\n",
      " ARIMA(3,0,0)(0,0,0)[0] intercept   : AIC=193.786, Time=0.05 sec"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ARIMA(2,0,0)(0,0,0)[0] intercept   : AIC=195.301, Time=0.03 sec\n",
      " ARIMA(4,0,0)(0,0,0)[0] intercept   : AIC=195.733, Time=0.07 sec\n",
      " ARIMA(3,0,1)(0,0,0)[0] intercept   : AIC=195.660, Time=0.10 sec\n",
      " ARIMA(2,0,1)(0,0,0)[0] intercept   : AIC=194.196, Time=0.05 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(4,0,1)(0,0,0)[0] intercept   : AIC=197.027, Time=0.09 sec\n",
      "\n",
      "Best model:  ARIMA(3,0,0)(0,0,0)[0] intercept\n",
      "Total fit time: 0.771 seconds\n",
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   56\n",
      "Model:               SARIMAX(3, 0, 0)   Log Likelihood                 -91.893\n",
      "Date:                Tue, 10 Jun 2025   AIC                            193.786\n",
      "Time:                        16:43:11   BIC                            203.913\n",
      "Sample:                             0   HQIC                           197.712\n",
      "                                 - 56                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept      0.4082      0.370      1.103      0.270      -0.317       1.134\n",
      "ar.L1          1.2053      0.147      8.204      0.000       0.917       1.493\n",
      "ar.L2         -0.5549      0.231     -2.402      0.016      -1.008      -0.102\n",
      "ar.L3          0.2494      0.123      2.023      0.043       0.008       0.491\n",
      "sigma2         1.5053      0.272      5.535      0.000       0.972       2.038\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):                 0.89\n",
      "Prob(Q):                              0.96   Prob(JB):                         0.64\n",
      "Heteroskedasticity (H):               1.81   Skew:                             0.18\n",
      "Prob(H) (two-sided):                  0.20   Kurtosis:                         3.51\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "Varincia amostral dos resduos: 1.6696842315259302\n"
     ]
    }
   ],
   "source": [
    "# Best ARMA model\n",
    "y = intdef['i3']\n",
    "model = auto_arima(\n",
    "    y,\n",
    "    start_p=0,  \n",
    "    start_q=0,  \n",
    "    max_p=5,   \n",
    "    max_q=5,    \n",
    "    d=0,        \n",
    "    seasonal=False,  \n",
    "    trace=True,  \n",
    "    error_action='ignore',  \n",
    "    suppress_warnings=True,  \n",
    "    stepwise=True,  \n",
    "    information_criterion='aic'  \n",
    ")\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "residuals = model.resid()\n",
    "\n",
    "#Squared residuals\n",
    "squared_residuals = residuals**2\n",
    "\n",
    "# Variance of the residuals\n",
    "sample_variance = np.var(residuals, ddof=1) \n",
    "print(f\"Varincia amostral dos resduos: {sample_variance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39d8a0d9-e1f3-4a75-8968-d558ed29fc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ploting correlogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_acf(squared_residuals, lags=20, alpha=0.05, title='ACF function')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelao')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5275dd1a-7aac-461b-9578-df98fe12f77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lb_stat  lb_pvalue\n",
      "10  5.912655   0.822547\n"
     ]
    }
   ],
   "source": [
    "# Ljung-Box test\n",
    "lb_test = acorr_ljungbox(squared_residuals, lags=[10], return_df=True)\n",
    "print(lb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c491a3af-779c-4980-aaf8-748de7d2a05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Mcleod and Li\n",
    "#Regres the squared residual with q lags and calculate LM test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b984a048-4658-4661-bb03-e2849a02a761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:      squared_residuals   R-squared:                       0.172\n",
      "Model:                            OLS   Adj. R-squared:                 -0.065\n",
      "Method:                 Least Squares   F-statistic:                    0.7254\n",
      "Date:                Tue, 10 Jun 2025   Prob (F-statistic):              0.695\n",
      "Time:                        16:43:11   Log-Likelihood:                -104.42\n",
      "No. Observations:                  46   AIC:                             230.8\n",
      "Df Residuals:                      35   BIC:                             251.0\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.1856      0.706      1.679      0.102      -0.248       2.620\n",
      "lag_1          0.3073      0.169      1.816      0.078      -0.036       0.651\n",
      "lag_2         -0.0315      0.175     -0.180      0.858      -0.388       0.325\n",
      "lag_3          0.1973      0.186      1.061      0.296      -0.180       0.575\n",
      "lag_4         -0.0064      0.188     -0.034      0.973      -0.387       0.375\n",
      "lag_5         -0.2509      0.185     -1.356      0.184      -0.627       0.125\n",
      "lag_6          0.1493      0.186      0.803      0.427      -0.228       0.527\n",
      "lag_7         -0.1500      0.186     -0.806      0.426      -0.528       0.228\n",
      "lag_8          0.2035      0.186      1.094      0.282      -0.174       0.581\n",
      "lag_9         -0.1142      0.186     -0.613      0.544      -0.492       0.264\n",
      "lag_10         0.0197      0.159      0.124      0.902      -0.303       0.342\n",
      "==============================================================================\n",
      "Omnibus:                       21.523   Durbin-Watson:                   1.994\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               31.128\n",
      "Skew:                           1.518   Prob(JB):                     1.74e-07\n",
      "Kurtosis:                       5.650   Cond. No.                         11.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#Number of lags\n",
    "q = 10\n",
    "\n",
    "#Setting a dataframe\n",
    "df = pd.DataFrame({'squared_residuals': squared_residuals})\n",
    "\n",
    "# Adding squared residuals\n",
    "for lag in range(1, q + 1):\n",
    "    df[f'lag_{lag}'] = df['squared_residuals'].shift(lag)\n",
    "\n",
    "# Remove missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Set independent and dependent variable\n",
    "\n",
    "y = df['squared_residuals']\n",
    "X = df[[f'lag_{i}' for i in range(1, q + 1)]]\n",
    "\n",
    "# Regression\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "404ec6a9-001d-4d09-acd3-a6de222487e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistic (LM): 7.897292367376994\n",
      "Critical value (_10, =0.05): 18.307038053275146\n",
      "p-value: 0.6388686572328914\n",
      "The null hypothesis is NOT rejected: there is  NO conditional heteroskedasticity.\n"
     ]
    }
   ],
   "source": [
    "#Mcleod and li statistic\n",
    "\n",
    "n = len(y) ##observations\n",
    "\n",
    "r_squared = results.rsquared\n",
    "\n",
    "lm_stat = n * r_squared ##calculating statistic\n",
    "\n",
    "alpha = 0.05 ##significance level\n",
    "\n",
    "critical_value = chi2.ppf(1 - alpha, df=q) \n",
    "\n",
    "p_value = 1 - chi2.cdf(lm_stat, df=q)\n",
    "\n",
    "print(f\"Statistic (LM): {lm_stat}\")\n",
    "print(f\"Critical value (_{q}, ={alpha}): {critical_value}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "if lm_stat > critical_value:\n",
    "    print(\"The null hypothesis is rejected: there is conditional heteroskedasticity.\")\n",
    "else:\n",
    "    print(\"The null hypothesis is NOT rejected: there is  NO conditional heteroskedasticity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce3fbe90-6aac-42ef-bf14-91b6a75394cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARCH-M model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b769a047-82f2-44c8-ac18-6a2889f3efff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>assess</th>\n",
       "      <th>bdrms</th>\n",
       "      <th>lotsize</th>\n",
       "      <th>sqrft</th>\n",
       "      <th>colonial</th>\n",
       "      <th>lprice</th>\n",
       "      <th>lassess</th>\n",
       "      <th>llotsize</th>\n",
       "      <th>lsqrft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300.0</td>\n",
       "      <td>349.100006</td>\n",
       "      <td>4</td>\n",
       "      <td>6126.0</td>\n",
       "      <td>2438</td>\n",
       "      <td>1</td>\n",
       "      <td>5.703783</td>\n",
       "      <td>5.855359</td>\n",
       "      <td>8.720297</td>\n",
       "      <td>7.798934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>370.0</td>\n",
       "      <td>351.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>9903.0</td>\n",
       "      <td>2076</td>\n",
       "      <td>1</td>\n",
       "      <td>5.913503</td>\n",
       "      <td>5.862210</td>\n",
       "      <td>9.200593</td>\n",
       "      <td>7.638198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191.0</td>\n",
       "      <td>217.699997</td>\n",
       "      <td>3</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>1374</td>\n",
       "      <td>0</td>\n",
       "      <td>5.252274</td>\n",
       "      <td>5.383118</td>\n",
       "      <td>8.556414</td>\n",
       "      <td>7.225482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195.0</td>\n",
       "      <td>231.800003</td>\n",
       "      <td>3</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>1448</td>\n",
       "      <td>1</td>\n",
       "      <td>5.273000</td>\n",
       "      <td>5.445875</td>\n",
       "      <td>8.433811</td>\n",
       "      <td>7.277938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>373.0</td>\n",
       "      <td>319.100006</td>\n",
       "      <td>4</td>\n",
       "      <td>6095.0</td>\n",
       "      <td>2514</td>\n",
       "      <td>1</td>\n",
       "      <td>5.921578</td>\n",
       "      <td>5.765504</td>\n",
       "      <td>8.715224</td>\n",
       "      <td>7.829630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>295.0</td>\n",
       "      <td>318.299988</td>\n",
       "      <td>3</td>\n",
       "      <td>6056.0</td>\n",
       "      <td>1837</td>\n",
       "      <td>1</td>\n",
       "      <td>5.686975</td>\n",
       "      <td>5.762994</td>\n",
       "      <td>8.708805</td>\n",
       "      <td>7.515889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>236.0</td>\n",
       "      <td>259.399994</td>\n",
       "      <td>3</td>\n",
       "      <td>5828.0</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>5.463832</td>\n",
       "      <td>5.558371</td>\n",
       "      <td>8.670429</td>\n",
       "      <td>7.447168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>202.5</td>\n",
       "      <td>258.100006</td>\n",
       "      <td>3</td>\n",
       "      <td>6341.0</td>\n",
       "      <td>1574</td>\n",
       "      <td>0</td>\n",
       "      <td>5.310740</td>\n",
       "      <td>5.553347</td>\n",
       "      <td>8.754792</td>\n",
       "      <td>7.361375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>219.0</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>6362.0</td>\n",
       "      <td>1185</td>\n",
       "      <td>0</td>\n",
       "      <td>5.389072</td>\n",
       "      <td>5.446737</td>\n",
       "      <td>8.758098</td>\n",
       "      <td>7.077498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>242.0</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4950.0</td>\n",
       "      <td>1774</td>\n",
       "      <td>1</td>\n",
       "      <td>5.488938</td>\n",
       "      <td>5.529429</td>\n",
       "      <td>8.507143</td>\n",
       "      <td>7.480992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    price      assess  bdrms  lotsize  sqrft  colonial    lprice   lassess  \\\n",
       "0   300.0  349.100006      4   6126.0   2438         1  5.703783  5.855359   \n",
       "1   370.0  351.500000      3   9903.0   2076         1  5.913503  5.862210   \n",
       "2   191.0  217.699997      3   5200.0   1374         0  5.252274  5.383118   \n",
       "3   195.0  231.800003      3   4600.0   1448         1  5.273000  5.445875   \n",
       "4   373.0  319.100006      4   6095.0   2514         1  5.921578  5.765504   \n",
       "..    ...         ...    ...      ...    ...       ...       ...       ...   \n",
       "83  295.0  318.299988      3   6056.0   1837         1  5.686975  5.762994   \n",
       "84  236.0  259.399994      3   5828.0   1715         0  5.463832  5.558371   \n",
       "85  202.5  258.100006      3   6341.0   1574         0  5.310740  5.553347   \n",
       "86  219.0  232.000000      2   6362.0   1185         0  5.389072  5.446737   \n",
       "87  242.0  252.000000      4   4950.0   1774         1  5.488938  5.529429   \n",
       "\n",
       "    llotsize    lsqrft  \n",
       "0   8.720297  7.798934  \n",
       "1   9.200593  7.638198  \n",
       "2   8.556414  7.225482  \n",
       "3   8.433811  7.277938  \n",
       "4   8.715224  7.829630  \n",
       "..       ...       ...  \n",
       "83  8.708805  7.515889  \n",
       "84  8.670429  7.447168  \n",
       "85  8.754792  7.361375  \n",
       "86  8.758098  7.077498  \n",
       "87  8.507143  7.480992  \n",
       "\n",
       "[88 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data\n",
    "data2 = wd.data('hprice1')\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41097662-891f-4520-96ca-cda847d25739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the data\n",
    "price = pd.Series(data2['price'])\n",
    "lotsize = pd.Series(data2['lotsize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8233010-8b3a-4b19-9a85-42ce8f37a591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      5,   Neg. LLF: 532.2277424861413\n",
      "Iteration:      2,   Func. Count:      8,   Neg. LLF: 532.2277428103741\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 532.2277424861413\n",
      "            Iterations: 2\n",
      "            Function evaluations: 8\n",
      "            Gradient evaluations: 2\n",
      "                           AR - ARCH Model Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.000\n",
      "Mean Model:                        AR   Adj. R-squared:                  0.000\n",
      "Vol Model:                       ARCH   Log-Likelihood:               -532.228\n",
      "Distribution:                  Normal   AIC:                           1070.46\n",
      "Method:            Maximum Likelihood   BIC:                           1077.89\n",
      "                                        No. Observations:                   88\n",
      "Date:                Tue, Jun 10 2025   Df Residuals:                       87\n",
      "Time:                        16:43:11   Df Model:                            1\n",
      "                                 Mean Model                                 \n",
      "============================================================================\n",
      "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
      "----------------------------------------------------------------------------\n",
      "Const        293.5672      9.140     32.118 2.456e-226 [2.757e+02,3.115e+02]\n",
      "                              Volatility Model                              \n",
      "============================================================================\n",
      "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
      "----------------------------------------------------------------------------\n",
      "omega       9387.1488   2534.177      3.704  2.120e-04 [4.420e+03,1.435e+04]\n",
      "alpha[1]       0.0000  8.301e-02      0.000      1.000     [ -0.163,  0.163]\n",
      "============================================================================\n",
      "\n",
      "Covariance estimator: robust\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 1.043e+04. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 0.1 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fit an ARCH-M model\n",
    "# Here, we assume that the mean of 'price' depends on its own conditional variance\n",
    "arch_m_model = arch_model(price, mean='ARX', lags=0, vol='ARCH', p=1, dist='normal')\n",
    "\n",
    "arch_m_results = arch_m_model.fit()\n",
    "\n",
    "print(arch_m_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "677f2fd0-e0b8-4846-8e55-1aee43d27d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Squared Residuals: 917854.5452987101\n"
     ]
    }
   ],
   "source": [
    "#Assessing the fit\n",
    "#SSR\n",
    "residuals = arch_m_results.resid\n",
    "\n",
    "ssr = np.sum(residuals**2)\n",
    "\n",
    "print(f\"Sum of Squared Residuals: {ssr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a053d0e6-40fc-4f8a-9d32-b4afb706c42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      6,   Neg. LLF: 563.261807855821\n",
      "Iteration:      2,   Func. Count:     12,   Neg. LLF: 531.4224465140848\n",
      "Iteration:      3,   Func. Count:     17,   Neg. LLF: 531.4222676452918\n",
      "Iteration:      4,   Func. Count:     22,   Neg. LLF: 531.4220627049029\n",
      "Iteration:      5,   Func. Count:     27,   Neg. LLF: 531.4570118664141\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 531.4220627022942\n",
      "            Iterations: 6\n",
      "            Function evaluations: 31\n",
      "            Gradient evaluations: 5\n",
      "                           AR - GARCH Model Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.000\n",
      "Mean Model:                        AR   Adj. R-squared:                  0.000\n",
      "Vol Model:                      GARCH   Log-Likelihood:               -531.422\n",
      "Distribution:                  Normal   AIC:                           1070.84\n",
      "Method:            Maximum Likelihood   BIC:                           1080.75\n",
      "                                        No. Observations:                   88\n",
      "Date:                Tue, Jun 10 2025   Df Residuals:                       87\n",
      "Time:                        16:43:11   Df Model:                            1\n",
      "                                 Mean Model                                 \n",
      "============================================================================\n",
      "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
      "----------------------------------------------------------------------------\n",
      "Const        293.5498     11.609     25.287 4.467e-141 [2.708e+02,3.163e+02]\n",
      "                               Volatility Model                              \n",
      "=============================================================================\n",
      "                 coef    std err          t      P>|t|       95.0% Conf. Int.\n",
      "-----------------------------------------------------------------------------\n",
      "omega       1043.0142   1001.111      1.042      0.297 [-9.191e+02,3.005e+03]\n",
      "alpha[1]   8.0008e-09  2.755e-02  2.904e-07      1.000 [-5.399e-02,5.399e-02]\n",
      "beta[1]        0.9065  9.226e-02      9.826  8.736e-23      [  0.726,  1.087]\n",
      "=============================================================================\n",
      "\n",
      "Covariance estimator: robust\n",
      "Sum of Squared Residuals: 917854.5452987101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 1.043e+04. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 0.1 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Comparing to a vol=GARCH\n",
    "arch_m_model2 = arch_model(price, mean='ARX', lags=0, p=1, dist='normal')\n",
    "\n",
    "arch_m_results2 = arch_m_model2.fit()\n",
    "\n",
    "print(arch_m_results2.summary())\n",
    "\n",
    "#SSR\n",
    "residuals2 = arch_m_results2.resid\n",
    "\n",
    "ssr2 = np.sum(residuals**2)\n",
    "\n",
    "print(f\"Sum of Squared Residuals: {ssr2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "323a6417-814d-4f77-ba18-aabc100d6b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lb_stat  lb_pvalue\n",
      "10  2.416325    0.99204\n",
      "     lb_stat  lb_pvalue\n",
      "10  2.416325    0.99204\n"
     ]
    }
   ],
   "source": [
    "# Perform Ljung-Box Q-test on squared residuals\n",
    "\n",
    "# Compute squared residuals\n",
    "res_sq1 = residuals**2 ## vector of squared residuals from vol = ARMA model\n",
    "res_sq2 = residuals**2 ## vector of squared residuals from vol = GARCH model\n",
    "\n",
    "lb_test1 = acorr_ljungbox(res_sq1, lags=[10], return_df=True)  # Test up to lag 10\n",
    "print(lb_test1)\n",
    "\n",
    "# Perform Ljung-Box Q-test on squared residuals\n",
    "lb_test2 = acorr_ljungbox(res_sq2, lags=[10], return_df=True)  # Test up to lag 10\n",
    "print(lb_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bb38391-ae3a-4069-a5ac-bc9af4e06208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diagnostich checks for model adequacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "744ab7bd-cdc4-478b-8fc9-0e28d760231a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ljung-Box test on residuals:\n",
      "       lb_stat     lb_pvalue\n",
      "10  157.977209  8.472276e-29\n",
      "\n",
      "Ljung-Box test on squared residuals:\n",
      "      lb_stat  lb_pvalue\n",
      "10  42.879431   0.000005\n"
     ]
    }
   ],
   "source": [
    "#Ljung-Box test\n",
    "\n",
    "# Extract standardized residuals\n",
    "residuals = res.resid\n",
    "squared_residuals = residuals**2\n",
    "\n",
    "# Ljung-Box test on residuals\n",
    "lb_test_residuals = acorr_ljungbox(residuals, lags=[10], return_df=True)\n",
    "print(\"Ljung-Box test on residuals:\")\n",
    "print(lb_test_residuals)\n",
    "\n",
    "# Ljung-Box test on squared residuals\n",
    "lb_test_squared_residuals = acorr_ljungbox(squared_residuals, lags=[10], return_df=True)\n",
    "print(\"\\nLjung-Box test on squared residuals:\")\n",
    "print(lb_test_squared_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33313257-d937-4ef0-bcf0-27e485dee1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasted Mean (Next 10 Steps):\n",
      "h.01    4.84505\n",
      "h.02    4.84505\n",
      "h.03    4.84505\n",
      "h.04    4.84505\n",
      "h.05    4.84505\n",
      "h.06    4.84505\n",
      "h.07    4.84505\n",
      "h.08    4.84505\n",
      "h.09    4.84505\n",
      "h.10    4.84505\n",
      "Name: 55, dtype: float64\n",
      "\n",
      "Forecasted Variance (Next 10 Steps):\n",
      "h.01    15.573149\n",
      "h.02    16.515288\n",
      "h.03    17.457427\n",
      "h.04    18.399566\n",
      "h.05    19.341705\n",
      "h.06    20.283844\n",
      "h.07    21.225983\n",
      "h.08    22.168122\n",
      "h.09    23.110261\n",
      "h.10    24.052400\n",
      "Name: 55, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "##Future values of yt\n",
    "#After Garch(1,1)\n",
    "# Forecast future values\n",
    "\n",
    "# Forecast the next 10 values\n",
    "forecast_horizon = 10\n",
    "forecasts = res.forecast(horizon=forecast_horizon)\n",
    "\n",
    "# Extract the forecasted mean (conditional mean) and variance (conditional variance)\n",
    "forecasted_mean = forecasts.mean.iloc[-1]  # Forecasted mean for the next 10 steps\n",
    "forecasted_variance = forecasts.variance.iloc[-1]  # Forecasted variance for the next 10 steps\n",
    "\n",
    "# Print the forecasted values\n",
    "print(\"Forecasted Mean (Next 10 Steps):\")\n",
    "print(forecasted_mean)\n",
    "\n",
    "print(\"\\nForecasted Variance (Next 10 Steps):\")\n",
    "print(forecasted_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdcf7581-45b0-4d55-bd87-4e2fd7948b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Other nmodels of conditional variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f263a88f-0a96-4acf-8529-725215ec78ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      1,   Func. Count:      6,   Neg. LLF: 136.1395826789892\n",
      "Iteration:      2,   Func. Count:     12,   Neg. LLF: 7553.465259229088\n",
      "Iteration:      3,   Func. Count:     18,   Neg. LLF: 136.70557296383623\n",
      "Iteration:      4,   Func. Count:     24,   Neg. LLF: 124.33691392297254\n",
      "Iteration:      5,   Func. Count:     30,   Neg. LLF: 122.3830408453359\n",
      "Iteration:      6,   Func. Count:     35,   Neg. LLF: 122.71164259681655\n",
      "Iteration:      7,   Func. Count:     41,   Neg. LLF: 122.22550402835286\n",
      "Iteration:      8,   Func. Count:     46,   Neg. LLF: 122.21385830757879\n",
      "Iteration:      9,   Func. Count:     51,   Neg. LLF: 122.21370995923758\n",
      "Iteration:     10,   Func. Count:     56,   Neg. LLF: 122.21370888353024\n",
      "Iteration:     11,   Func. Count:     60,   Neg. LLF: 122.21370898528826\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 122.21370888353024\n",
      "            Iterations: 11\n",
      "            Function evaluations: 60\n",
      "            Gradient evaluations: 11\n",
      "                     Constant Mean - GARCH Model Results                      \n",
      "==============================================================================\n",
      "Dep. Variable:                     i3   R-squared:                       0.000\n",
      "Mean Model:             Constant Mean   Adj. R-squared:                  0.000\n",
      "Vol Model:                      GARCH   Log-Likelihood:               -122.214\n",
      "Distribution:                  Normal   AIC:                           252.427\n",
      "Method:            Maximum Likelihood   BIC:                           260.529\n",
      "                                        No. Observations:                   56\n",
      "Date:                Tue, Jun 10 2025   Df Residuals:                       55\n",
      "Time:                        16:43:11   Df Model:                            1\n",
      "                               Mean Model                               \n",
      "========================================================================\n",
      "                 coef    std err          t      P>|t|  95.0% Conf. Int.\n",
      "------------------------------------------------------------------------\n",
      "mu             4.8451      0.242     20.000  5.453e-89 [  4.370,  5.320]\n",
      "                              Volatility Model                             \n",
      "===========================================================================\n",
      "                 coef    std err          t      P>|t|     95.0% Conf. Int.\n",
      "---------------------------------------------------------------------------\n",
      "omega          0.9421      0.503      1.874  6.091e-02 [-4.314e-02,  1.927]\n",
      "alpha[1]       1.0000      0.328      3.045  2.329e-03    [  0.356,  1.644]\n",
      "beta[1]    1.8607e-14      0.154  1.212e-13      1.000    [ -0.301,  0.301]\n",
      "===========================================================================\n",
      "\n",
      "Covariance estimator: robust\n"
     ]
    }
   ],
   "source": [
    "##IGARCH\n",
    "# Specify the IGARCH(1,1) model\n",
    "model_igarch = arch_model(intdef['i3'], vol='GARCH', p=1, q=1, o=0, mean='Constant', rescale=False)\n",
    "\n",
    "# Set IGARCH constraint\n",
    "# This is the key part - we tell the model that alpha + beta should equal 1\n",
    "# For GARCH(1,1), the parameters are [omega, alpha, beta]\n",
    "model_igarch.volatility.constraint = lambda params: params[1] + params[2] - 1.0\n",
    "\n",
    "# Fit the model\n",
    "res_igarch = model_igarch.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(res_igarch.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "134acc23-3d4f-48db-8a17-89720a164e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Least Squares - GARCH Model Results                      \n",
      "==============================================================================\n",
      "Dep. Variable:                     i3   R-squared:                      -0.542\n",
      "Mean Model:             Least Squares   Adj. R-squared:                 -0.571\n",
      "Vol Model:                      GARCH   Log-Likelihood:               -118.839\n",
      "Distribution:                  Normal   AIC:                           247.678\n",
      "Method:            Maximum Likelihood   BIC:                           257.805\n",
      "                                        No. Observations:                   56\n",
      "Date:                Tue, Jun 10 2025   Df Residuals:                       54\n",
      "Time:                        16:43:11   Df Model:                            2\n",
      "                               Mean Model                               \n",
      "========================================================================\n",
      "                 coef    std err          t      P>|t|  95.0% Conf. Int.\n",
      "------------------------------------------------------------------------\n",
      "Const          2.7660      0.118     23.379 7.056e-121 [  2.534,  2.998]\n",
      "dummy          2.2003      0.169     13.012  1.052e-38 [  1.869,  2.532]\n",
      "                              Volatility Model                             \n",
      "===========================================================================\n",
      "                 coef    std err          t      P>|t|     95.0% Conf. Int.\n",
      "---------------------------------------------------------------------------\n",
      "omega          0.2098      0.113      1.864  6.227e-02 [-1.075e-02,  0.430]\n",
      "alpha[1]       1.0000      0.201      4.983  6.267e-07    [  0.607,  1.393]\n",
      "beta[1]        0.0000  9.647e-02      0.000      1.000    [ -0.189,  0.189]\n",
      "===========================================================================\n",
      "\n",
      "Covariance estimator: robust\n"
     ]
    }
   ],
   "source": [
    "##Models with explanatory variables\n",
    "intdef['dummy'] = (intdef['year'] > 1993).astype(int)\n",
    "\n",
    "# with column names for proper interpretation in the results\n",
    "X = pd.DataFrame(intdef['dummy'])\n",
    "\n",
    "# Use the X parameter (not x) to include exogenous variables in the mean equation\n",
    "model_exp = arch_model(intdef['i3'], x=X, mean='LS', vol='GARCH', p=1, q=1)\n",
    "res_exp = model_exp.fit(disp='off')  # Set disp='off' to reduce verbose output\n",
    "print(res_exp.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8020b49a-35b9-4523-8669-5c222a90eb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Models with assymetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28efcf2d-5414-4612-8718-7802c7c35fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      5,   Func. Count:     40,   Neg. LLF: 54.79354371713068\n",
      "Iteration:     10,   Func. Count:     71,   Neg. LLF: 54.77156395912378\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 54.77156400104625\n",
      "            Iterations: 10\n",
      "            Function evaluations: 71\n",
      "            Gradient evaluations: 10\n",
      "                   Constant Mean - GJR-GARCH Model Results                    \n",
      "==============================================================================\n",
      "Dep. Variable:                returns   R-squared:                       0.000\n",
      "Mean Model:             Constant Mean   Adj. R-squared:                  0.000\n",
      "Vol Model:                  GJR-GARCH   Log-Likelihood:               -54.7716\n",
      "Distribution:                  Normal   AIC:                           119.543\n",
      "Method:            Maximum Likelihood   BIC:                           131.873\n",
      "                                        No. Observations:                   87\n",
      "Date:                Tue, Jun 10 2025   Df Residuals:                       86\n",
      "Time:                        16:43:11   Df Model:                            1\n",
      "                                 Mean Model                                \n",
      "===========================================================================\n",
      "                 coef    std err          t      P>|t|     95.0% Conf. Int.\n",
      "---------------------------------------------------------------------------\n",
      "mu             0.0515  6.157e-02      0.837      0.403 [-6.913e-02,  0.172]\n",
      "                               Volatility Model                              \n",
      "=============================================================================\n",
      "                 coef    std err          t      P>|t|       95.0% Conf. Int.\n",
      "-----------------------------------------------------------------------------\n",
      "omega          0.0218  3.075e-02      0.709      0.478 [-3.846e-02,8.209e-02]\n",
      "alpha[1]   1.4108e-03  3.188e-02  4.425e-02      0.965 [-6.107e-02,6.389e-02]\n",
      "gamma[1]       0.4657      0.666      0.700      0.484      [ -0.839,  1.770]\n",
      "beta[1]        0.7658  8.586e-02      8.919  4.723e-19      [  0.597,  0.934]\n",
      "=============================================================================\n",
      "\n",
      "Covariance estimator: robust\n"
     ]
    }
   ],
   "source": [
    "##TARCH model\n",
    "#Preparing the data\n",
    "# Load the dataset\n",
    "data = wd.data('hprice1')\n",
    "\n",
    "# Calculate percentage changes (returns) in house prices\n",
    "data['returns'] = data['price'].pct_change().dropna()\n",
    "\n",
    "# Drop the first row which contains NaN due to the pct_change operation\n",
    "data = data.dropna()\n",
    "\n",
    "# Fit the TARCH model (GJR-GARCH)\n",
    "# The `vol='GARCH'` parameter specifies the GARCH model, and `p=1, o=1, q=1` specifies the order of the model.\n",
    "# The `o=1` parameter allows for asymmetric effects (TARCH/GJR-GARCH).\n",
    "model = arch_model(data['returns'], vol='Garch', p=1, o=1, q=1)\n",
    "results = model.fit(update_freq=5)\n",
    "\n",
    "# Display the summary of the model\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8aea5415-97cc-49e4-a4e2-8d37cf9b57ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      5,   Func. Count:     45,   Neg. LLF: 733703268482.5905\n",
      "Iteration:     10,   Func. Count:     88,   Neg. LLF: 58.73319032470346\n",
      "Iteration:     15,   Func. Count:    123,   Neg. LLF: 114131593.59848584\n",
      "Iteration:     20,   Func. Count:    163,   Neg. LLF: 53615986.5867397\n",
      "Iteration:     25,   Func. Count:    203,   Neg. LLF: 544.9209076519791\n",
      "Iteration:     30,   Func. Count:    252,   Neg. LLF: 7638943575.917934\n",
      "Iteration:     35,   Func. Count:    299,   Neg. LLF: 73159103.75039847\n",
      "Iteration:     40,   Func. Count:    354,   Neg. LLF: 1281595309.1340709\n",
      "Iteration:     45,   Func. Count:    401,   Neg. LLF: 42.91576272057816\n",
      "Iteration:     50,   Func. Count:    439,   Neg. LLF: 4723615.5789498715\n",
      "Iteration:     55,   Func. Count:    492,   Neg. LLF: 25609898.405331247\n",
      "Iteration:     60,   Func. Count:    551,   Neg. LLF: 26351143.836617965\n",
      "Iteration:     65,   Func. Count:    613,   Neg. LLF: 27090436.782042835\n",
      "Iteration:     70,   Func. Count:    686,   Neg. LLF: 95.46325694623482\n",
      "Iteration:     75,   Func. Count:    765,   Neg. LLF: 106.94374440409436\n",
      "Iteration:     80,   Func. Count:    844,   Neg. LLF: 26192264.239280567\n",
      "Iteration:     85,   Func. Count:    924,   Neg. LLF: 38629516.60009847\n",
      "Iteration:     90,   Func. Count:  1e+03,   Neg. LLF: 38629505.66329372\n",
      "Iteration:     95,   Func. Count: 1.08e+03,   Neg. LLF: 1057615174481.2233\n",
      "Iteration limit reached    (Exit mode 9)\n",
      "            Current function value: 42.02233522870204\n",
      "            Iterations: 100\n",
      "            Function evaluations: 1123\n",
      "            Gradient evaluations: 99\n",
      "                     Constant Mean - EGARCH Model Results                     \n",
      "==============================================================================\n",
      "Dep. Variable:                returns   R-squared:                       0.000\n",
      "Mean Model:             Constant Mean   Adj. R-squared:                  0.000\n",
      "Vol Model:                     EGARCH   Log-Likelihood:               -42.0223\n",
      "Distribution:                  Normal   AIC:                           94.0447\n",
      "Method:            Maximum Likelihood   BIC:                           106.374\n",
      "                                        No. Observations:                   87\n",
      "Date:                Tue, Jun 10 2025   Df Residuals:                       86\n",
      "Time:                        16:43:11   Df Model:                            1\n",
      "                                 Mean Model                                 \n",
      "============================================================================\n",
      "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
      "----------------------------------------------------------------------------\n",
      "mu             0.0277  1.808e-03     15.316  5.937e-53 [2.415e-02,3.124e-02]\n",
      "                               Volatility Model                               \n",
      "==============================================================================\n",
      "                  coef    std err          t      P>|t|       95.0% Conf. Int.\n",
      "------------------------------------------------------------------------------\n",
      "omega          -0.1524  6.072e-06 -2.510e+04      0.000      [ -0.152, -0.152]\n",
      "alpha[1]       -0.4807  1.341e-03   -358.439      0.000      [ -0.483, -0.478]\n",
      "gamma[1]   -1.4900e-04  1.810e-03 -8.233e-02      0.934 [-3.696e-03,3.398e-03]\n",
      "beta[1]         0.9402  4.780e-11  1.967e+10      0.000      [  0.940,  0.940]\n",
      "==============================================================================\n",
      "\n",
      "Covariance estimator: robust\n",
      "WARNING: The optimizer did not indicate successful convergence. The message was Iteration limit reached.\n",
      "See convergence_flag.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daves\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:768: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
      "Iteration limit reached\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##EGARCH model\n",
    "# Fit the EGARCH model\n",
    "# The `vol='EGARCH'` parameter specifies the Exponential GARCH model\n",
    "# p=1, o=1, q=1 specifies the order of the model with asymmetric effects\n",
    "egarch_model = arch_model(data['returns'], vol='EGARCH', p=1, o=1, q=1)\n",
    "egarch_results = egarch_model.fit(update_freq=5)\n",
    "\n",
    "# Display the summary of the model\n",
    "print(egarch_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f7d94f2-d14f-4ff7-885a-7acad6de04ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Testing for leverage effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02724d5e-f809-434e-882f-d73646d5ca26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      5,   Func. Count:     37,   Neg. LLF: 54.97588561855231\n",
      "Iteration:     10,   Func. Count:     62,   Neg. LLF: 60.32165994767513\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 54.869762636824035\n",
      "            Iterations: 11\n",
      "            Function evaluations: 66\n",
      "            Gradient evaluations: 10\n",
      "                     Constant Mean - GARCH Model Results                      \n",
      "==============================================================================\n",
      "Dep. Variable:                returns   R-squared:                       0.000\n",
      "Mean Model:             Constant Mean   Adj. R-squared:                  0.000\n",
      "Vol Model:                      GARCH   Log-Likelihood:               -54.8698\n",
      "Distribution:                  Normal   AIC:                           117.740\n",
      "Method:            Maximum Likelihood   BIC:                           127.603\n",
      "                                        No. Observations:                   87\n",
      "Date:                Tue, Jun 10 2025   Df Residuals:                       86\n",
      "Time:                        16:43:11   Df Model:                            1\n",
      "                                 Mean Model                                \n",
      "===========================================================================\n",
      "                 coef    std err          t      P>|t|     95.0% Conf. Int.\n",
      "---------------------------------------------------------------------------\n",
      "mu             0.0794  4.669e-02      1.700  8.907e-02 [-1.212e-02,  0.171]\n",
      "                               Volatility Model                              \n",
      "=============================================================================\n",
      "                 coef    std err          t      P>|t|       95.0% Conf. Int.\n",
      "-----------------------------------------------------------------------------\n",
      "omega      1.7172e-03  7.218e-03      0.238      0.812 [-1.243e-02,1.586e-02]\n",
      "alpha[1]   3.3108e-14  1.707e-02  1.940e-12      1.000 [-3.345e-02,3.345e-02]\n",
      "beta[1]        1.0000  3.653e-02     27.377 5.116e-165      [  0.928,  1.072]\n",
      "=============================================================================\n",
      "\n",
      "Covariance estimator: robust\n"
     ]
    }
   ],
   "source": [
    "# Fit a standard GARCH(1,1) model\n",
    "garch_model = arch_model(data['returns'], vol='GARCH', p=1, q=1)\n",
    "garch_results = garch_model.fit(update_freq=5)\n",
    "\n",
    "# Print the summary\n",
    "print(garch_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75dc203d-6172-4fe3-96f9-22d1f9b7f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get residuals and conditional variances\n",
    "residuals = garch_results.resid\n",
    "conditional_variances = garch_results.conditional_volatility ** 2\n",
    "\n",
    "# Calculate standardized residuals\n",
    "standardized_residuals = residuals / np.sqrt(conditional_variances)\n",
    "\n",
    "# Add standardized residuals to the original DataFrame\n",
    "data['standardized_residuals'] = standardized_residuals\n",
    "data['squared_standardized_residuals'] = standardized_residuals ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb6a38c3-070f-420d-a7cd-194289636a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Lagged Variables\n",
    "# Number of lags to include\n",
    "lags = 2\n",
    "\n",
    "# Create lagged variables\n",
    "for i in range(1, lags + 1):\n",
    "    data[f's_lag_{i}'] = data['standardized_residuals'].shift(i)\n",
    "\n",
    "# Drop rows with NaN values (due to shifting)\n",
    "data_cleaned = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11a9875f-410f-4ff8-86af-be0eff304df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  OLS Regression Results                                  \n",
      "==========================================================================================\n",
      "Dep. Variable:     squared_standardized_residuals   R-squared:                       0.005\n",
      "Model:                                        OLS   Adj. R-squared:                 -0.019\n",
      "Method:                             Least Squares   F-statistic:                    0.2164\n",
      "Date:                            Tue, 10 Jun 2025   Prob (F-statistic):              0.806\n",
      "Time:                                    16:43:11   Log-Likelihood:                -193.17\n",
      "No. Observations:                              85   AIC:                             392.3\n",
      "Df Residuals:                                  82   BIC:                             399.7\n",
      "Df Model:                                       2                                         \n",
      "Covariance Type:                        nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.9505      0.259      3.665      0.000       0.435       1.466\n",
      "s_lag_1        0.1339      0.276      0.485      0.629      -0.415       0.683\n",
      "s_lag_2       -0.0753      0.276     -0.273      0.786      -0.624       0.473\n",
      "==============================================================================\n",
      "Omnibus:                      121.509   Durbin-Watson:                   1.972\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2640.701\n",
      "Skew:                           4.932   Prob(JB):                         0.00\n",
      "Kurtosis:                      28.462   Cond. No.                         1.38\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#Regression of Standardized Residuals\n",
    "\n",
    "# Define dependent and independent variables\n",
    "X = data_cleaned[[f's_lag_{i}' for i in range(1, lags + 1)]]\n",
    "X = sm.add_constant(X)  # Add a constant term\n",
    "y = data_cleaned['squared_standardized_residuals']\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Print regression results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45469f6f-9c1c-4f00-84b4-28295631cc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  OLS Regression Results                                  \n",
      "==========================================================================================\n",
      "Dep. Variable:     squared_standardized_residuals   R-squared:                       0.020\n",
      "Model:                                        OLS   Adj. R-squared:                  0.009\n",
      "Method:                             Least Squares   F-statistic:                     1.727\n",
      "Date:                            Tue, 10 Jun 2025   Prob (F-statistic):              0.192\n",
      "Time:                                    16:43:11   Log-Likelihood:                -192.52\n",
      "No. Observations:                              85   AIC:                             389.0\n",
      "Df Residuals:                                  83   BIC:                             393.9\n",
      "Df Model:                                       1                                         \n",
      "Covariance Type:                        nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.3152      0.378      3.483      0.001       0.564       2.066\n",
      "d_lag_1       -0.6747      0.513     -1.314      0.192      -1.696       0.346\n",
      "==============================================================================\n",
      "Omnibus:                      117.263   Durbin-Watson:                   1.916\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2289.036\n",
      "Skew:                           4.708   Prob(JB):                         0.00\n",
      "Kurtosis:                      26.615   Cond. No.                         2.73\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daves\\AppData\\Local\\Temp\\ipykernel_20824\\3349678867.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['d_lag_1'] = (data_cleaned['standardized_residuals'].shift(1) < 0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "##Sign Bias Test\n",
    "# Create dummy variable for negative shocks\n",
    "data_cleaned['d_lag_1'] = (data_cleaned['standardized_residuals'].shift(1) < 0).astype(int)\n",
    "\n",
    "# Define dependent and independent variables for Sign Bias test\n",
    "X_sign_bias = data_cleaned[['d_lag_1']]\n",
    "X_sign_bias = sm.add_constant(X_sign_bias)  # Add a constant term\n",
    "y_sign_bias = data_cleaned['squared_standardized_residuals']\n",
    "\n",
    "# Fit the regression model for Sign Bias test\n",
    "model_sign_bias = sm.OLS(y_sign_bias, X_sign_bias)\n",
    "results_sign_bias = model_sign_bias.fit()\n",
    "\n",
    "# Print regression results\n",
    "print(results_sign_bias.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64059776-7541-49ec-85fb-c5f6b01bd868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  OLS Regression Results                                  \n",
      "==========================================================================================\n",
      "Dep. Variable:     squared_standardized_residuals   R-squared:                       0.022\n",
      "Model:                                        OLS   Adj. R-squared:                 -0.014\n",
      "Method:                             Least Squares   F-statistic:                    0.6198\n",
      "Date:                            Tue, 10 Jun 2025   Prob (F-statistic):              0.604\n",
      "Time:                                    16:43:11   Log-Likelihood:                -192.43\n",
      "No. Observations:                              85   AIC:                             392.9\n",
      "Df Residuals:                                  81   BIC:                             402.6\n",
      "Df Model:                                       3                                         \n",
      "Covariance Type:                        nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   1.4024      0.478      2.936      0.004       0.452       2.353\n",
      "d_lag_1                -0.9123      0.802     -1.138      0.259      -2.508       0.683\n",
      "d_lag_1_s_lag_1        -0.2420      0.868     -0.279      0.781      -1.968       1.484\n",
      "(1-d_lag_1)_s_lag_1    -0.1194      0.393     -0.304      0.762      -0.902       0.663\n",
      "==============================================================================\n",
      "Omnibus:                      115.863   Durbin-Watson:                   1.855\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2190.790\n",
      "Skew:                           4.633   Prob(JB):                         0.00\n",
      "Kurtosis:                      26.081   Cond. No.                         5.38\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daves\\AppData\\Local\\Temp\\ipykernel_20824\\3175469283.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['d_lag_1_s_lag_1'] = data_cleaned['d_lag_1'] * data_cleaned['s_lag_1']\n",
      "C:\\Users\\daves\\AppData\\Local\\Temp\\ipykernel_20824\\3175469283.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['(1-d_lag_1)_s_lag_1'] = (1 - data_cleaned['d_lag_1']) * data_cleaned['s_lag_1']\n"
     ]
    }
   ],
   "source": [
    "##Generalized Sign Bias Test\n",
    "# Create interaction terms\n",
    "data_cleaned['d_lag_1_s_lag_1'] = data_cleaned['d_lag_1'] * data_cleaned['s_lag_1']\n",
    "data_cleaned['(1-d_lag_1)_s_lag_1'] = (1 - data_cleaned['d_lag_1']) * data_cleaned['s_lag_1']\n",
    "\n",
    "# Define dependent and independent variables for Generalized Sign Bias test\n",
    "X_gen_sign_bias = data_cleaned[['d_lag_1', 'd_lag_1_s_lag_1', '(1-d_lag_1)_s_lag_1']]\n",
    "X_gen_sign_bias = sm.add_constant(X_gen_sign_bias)  # Add a constant term\n",
    "y_gen_sign_bias = data_cleaned['squared_standardized_residuals']\n",
    "\n",
    "# Fit the regression model for Generalized Sign Bias test\n",
    "model_gen_sign_bias = sm.OLS(y_gen_sign_bias, X_gen_sign_bias)\n",
    "results_gen_sign_bias = model_gen_sign_bias.fit()\n",
    "\n",
    "# Print regression results\n",
    "print(results_gen_sign_bias.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36c362d9-0169-46fe-87cc-267469a011fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      5,   Func. Count:     37,   Neg. LLF: 100.70694079257935\n",
      "Iteration:     10,   Func. Count:     69,   Neg. LLF: 45.303333698263366\n",
      "Iteration:     15,   Func. Count:     99,   Neg. LLF: 45.19773762243316\n",
      "Iteration:     20,   Func. Count:    129,   Neg. LLF: 45.15953296176247\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 45.1595075510256\n",
      "            Iterations: 22\n",
      "            Function evaluations: 141\n",
      "            Gradient evaluations: 22\n",
      "                        Constant Mean - GARCH Model Results                         \n",
      "====================================================================================\n",
      "Dep. Variable:                      returns   R-squared:                       0.000\n",
      "Mean Model:                   Constant Mean   Adj. R-squared:                  0.000\n",
      "Vol Model:                            GARCH   Log-Likelihood:               -45.1595\n",
      "Distribution:      Standardized Student's t   AIC:                           100.319\n",
      "Method:                  Maximum Likelihood   BIC:                           112.649\n",
      "                                              No. Observations:                   87\n",
      "Date:                      Tue, Jun 10 2025   Df Residuals:                       86\n",
      "Time:                              16:43:12   Df Model:                            1\n",
      "                                  Mean Model                                 \n",
      "=============================================================================\n",
      "                 coef    std err          t      P>|t|       95.0% Conf. Int.\n",
      "-----------------------------------------------------------------------------\n",
      "mu             0.0223  3.817e-02      0.584      0.559 [-5.250e-02,9.712e-02]\n",
      "                              Volatility Model                             \n",
      "===========================================================================\n",
      "                 coef    std err          t      P>|t|     95.0% Conf. Int.\n",
      "---------------------------------------------------------------------------\n",
      "omega          0.1896      0.101      1.877  6.056e-02 [-8.411e-03,  0.388]\n",
      "alpha[1]       0.1883      0.147      1.279      0.201    [ -0.100,  0.477]\n",
      "beta[1]        0.0000      0.183      0.000      1.000    [ -0.359,  0.359]\n",
      "                              Distribution                              \n",
      "========================================================================\n",
      "                 coef    std err          t      P>|t|  95.0% Conf. Int.\n",
      "------------------------------------------------------------------------\n",
      "nu             3.3312      1.142      2.917  3.535e-03 [  1.093,  5.569]\n",
      "========================================================================\n",
      "\n",
      "Covariance estimator: robust\n"
     ]
    }
   ],
   "source": [
    "##Nonnormal errors\n",
    "#with a t-distribution\n",
    "# Fit a GARCH(1,1) model with Student's t-distribution\n",
    "garch_model = arch_model(data['returns'], vol='GARCH', p=1, q=1, dist='t')\n",
    "garch_results = garch_model.fit(update_freq=5)\n",
    "\n",
    "# Print the summary\n",
    "print(garch_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff011b27-8959-47f6-a563-b519cf395e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Multivariated GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "102fcb95-9e6e-4306-acb3-096e8e14a032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GARCH Model for returns:\n",
      "                     Constant Mean - GARCH Model Results                      \n",
      "==============================================================================\n",
      "Dep. Variable:                returns   R-squared:                       0.000\n",
      "Mean Model:             Constant Mean   Adj. R-squared:                  0.000\n",
      "Vol Model:                      GARCH   Log-Likelihood:               -53.6933\n",
      "Distribution:                  Normal   AIC:                           115.387\n",
      "Method:            Maximum Likelihood   BIC:                           125.157\n",
      "                                        No. Observations:                   85\n",
      "Date:                Tue, Jun 10 2025   Df Residuals:                       84\n",
      "Time:                        16:43:12   Df Model:                            1\n",
      "==============================================================================\n",
      "\n",
      "GARCH Model for returns2:\n",
      "                     Constant Mean - GARCH Model Results                      \n",
      "==============================================================================\n",
      "Dep. Variable:               returns2   R-squared:                       0.000\n",
      "Mean Model:             Constant Mean   Adj. R-squared:                  0.000\n",
      "Vol Model:                      GARCH   Log-Likelihood:               -39.8503\n",
      "Distribution:                  Normal   AIC:                           87.7006\n",
      "Method:            Maximum Likelihood   BIC:                           97.4712\n",
      "                                        No. Observations:                   85\n",
      "Date:                Tue, Jun 10 2025   Df Residuals:                       84\n",
      "Time:                        16:43:12   Df Model:                            1\n",
      "==============================================================================\n",
      "\n",
      "Unconditional Correlation Matrix:\n",
      "[[1.         0.85425671]\n",
      " [0.85425671 1.        ]]\n",
      "\n",
      "Optimized Parameters:\n",
      "A (ARCH effects):\n",
      "[[0.25969165 0.10168267]\n",
      " [0.03590754 0.28587491]]\n",
      "B (GARCH effects):\n",
      "[[0.24907408 0.02694756]\n",
      " [0.00251641 0.25629839]]\n",
      "C (Constant term):\n",
      "[[0.49123427 0.74437348]\n",
      " [0.8214328  0.4578267 ]]\n",
      "\n",
      "VECH Model Results with MLE:\n",
      "Last few conditional covariance matrices:\n",
      "Time 80:\n",
      "[[0.90461138 0.76408215]\n",
      " [0.8228661  0.74869049]]\n",
      "Time 81:\n",
      "[[0.8636914  0.76576028]\n",
      " [0.82378479 0.78591304]]\n",
      "Time 82:\n",
      "[[0.84913006 0.76877203]\n",
      " [0.82483468 0.80142882]]\n",
      "Time 83:\n",
      "[[0.84629974 0.76516234]\n",
      " [0.82353396 0.8015753 ]]\n",
      "Time 84:\n",
      "[[0.84230205 0.7641549 ]\n",
      " [0.82320928 0.80474482]]\n",
      "\n",
      "Forecasted Covariance Matrices:\n",
      "Horizon 1:\n",
      "[[0.84230205 0.7641549 ]\n",
      " [0.82320928 0.80474482]]\n",
      "Horizon 2:\n",
      "[[0.70102988 0.76496559]\n",
      " [0.82350433 0.66408151]]\n",
      "Horizon 3:\n",
      "[[0.66584264 0.76498743]\n",
      " [0.82350507 0.62802972]]\n",
      "Horizon 4:\n",
      "[[0.65707841 0.76498802]\n",
      " [0.82350507 0.61878971]]\n",
      "Horizon 5:\n",
      "[[0.65489547 0.76498804]\n",
      " [0.82350507 0.61642151]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daves\\AppData\\Local\\Temp\\ipykernel_20824\\2864482105.py:62: RuntimeWarning: invalid value encountered in log\n",
      "  log_likelihood += -0.5 * (np.log(det_H_t) + np.dot(returns_array[t], np.dot(inv_H_t, returns_array[t])))\n"
     ]
    }
   ],
   "source": [
    "##VECH Model\n",
    "\n",
    "# Preparing the data\n",
    "# Calculate percentage changes (returns) for the variables\n",
    "data['returns'] = data['price'].pct_change().dropna()\n",
    "data['returns2'] = data['assess'].pct_change().dropna()\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Prepare the returns data for multivariate GARCH\n",
    "returns = data[['returns', 'returns2']]\n",
    "\n",
    "# Number of assets\n",
    "n = returns.shape[1]\n",
    "\n",
    "# Step 1: Estimate univariate GARCH models for each return series\n",
    "garch_models = []\n",
    "for i in range(n):\n",
    "    model = arch_model(returns.iloc[:, i], vol='GARCH', p=1, q=1)\n",
    "    result = model.fit(disp='off')\n",
    "    garch_models.append(result)\n",
    "    print(f\"\\nGARCH Model for {returns.columns[i]}:\")\n",
    "    print(result.summary().tables[0])\n",
    "\n",
    "# Step 2: Implement the VECH model using MLE\n",
    "\n",
    "# Compute unconditional correlation matrix\n",
    "corr_const = np.corrcoef(returns.values.T)\n",
    "print(\"\\nUnconditional Correlation Matrix:\")\n",
    "print(corr_const)\n",
    "\n",
    "# Define the negative log-likelihood function\n",
    "def negative_log_likelihood(params, returns_array, corr_const):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood function for the VECH model.\n",
    "    \"\"\"\n",
    "    T, n = returns_array.shape\n",
    "    A = params[:n**2].reshape((n, n))  # ARCH effects\n",
    "    B = params[n**2:2*n**2].reshape((n, n))  # GARCH effects\n",
    "    C = (1 - A - B) * corr_const  # Constant term\n",
    "\n",
    "    H = np.zeros((T, n, n))  # Conditional covariance matrices\n",
    "    H[0] = corr_const.copy()\n",
    "\n",
    "    log_likelihood = 0\n",
    "    for t in range(1, T):\n",
    "        eps_t = returns_array[t-1].reshape(-1, 1)\n",
    "        eps_eps_t = np.dot(eps_t, eps_t.T)  # Cross-product of residuals\n",
    "\n",
    "        # VECH recursion\n",
    "        H[t] = C + A * eps_eps_t + B * H[t-1]\n",
    "\n",
    "        # Ensure positive definiteness\n",
    "        eigvals = np.linalg.eigvalsh(H[t])\n",
    "        if np.min(eigvals) <= 0:\n",
    "            H[t] = H[t] - np.min(eigvals) * np.eye(n) + 0.0001 * np.eye(n)\n",
    "\n",
    "        # Compute log-likelihood\n",
    "        inv_H_t = np.linalg.inv(H[t])\n",
    "        det_H_t = np.linalg.det(H[t])\n",
    "        log_likelihood += -0.5 * (np.log(det_H_t) + np.dot(returns_array[t], np.dot(inv_H_t, returns_array[t])))\n",
    "\n",
    "    return -log_likelihood  # Return negative log-likelihood for minimization\n",
    "\n",
    "# Initial parameter guesses\n",
    "n_params = 2 * n**2  # Number of parameters (A and B)\n",
    "initial_params = np.random.rand(n_params) * 0.1  # Small random values\n",
    "\n",
    "# Optimize the likelihood function\n",
    "result = minimize(\n",
    "    negative_log_likelihood,\n",
    "    initial_params,\n",
    "    args=(returns.values, corr_const),\n",
    "    method='L-BFGS-B',  # Use a constrained optimization method\n",
    "    bounds=[(0, 1)] * n_params  # Ensure parameters are between 0 and 1\n",
    ")\n",
    "\n",
    "# Extract optimized parameters\n",
    "optimized_params = result.x\n",
    "A_opt = optimized_params[:n**2].reshape((n, n))\n",
    "B_opt = optimized_params[n**2:2*n**2].reshape((n, n))\n",
    "C_opt = (1 - A_opt - B_opt) * corr_const\n",
    "\n",
    "print(\"\\nOptimized Parameters:\")\n",
    "print(\"A (ARCH effects):\")\n",
    "print(A_opt)\n",
    "print(\"B (GARCH effects):\")\n",
    "print(B_opt)\n",
    "print(\"C (Constant term):\")\n",
    "print(C_opt)\n",
    "\n",
    "# Step 3: Estimate the VECH model with optimized parameters\n",
    "T = returns.shape[0]  # Ensure T is correctly calculated\n",
    "H = np.zeros((T, n, n))  # Conditional covariance matrices\n",
    "H[0] = corr_const.copy()\n",
    "\n",
    "for t in range(1, T):\n",
    "    eps_t = returns.values[t-1].reshape(-1, 1)  # Access t-1, which is valid\n",
    "    eps_eps_t = np.dot(eps_t, eps_t.T)  # Cross-product of residuals\n",
    "\n",
    "    # VECH recursion with optimized parameters\n",
    "    H[t] = C_opt + A_opt * eps_eps_t + B_opt * H[t-1]\n",
    "\n",
    "    # Ensure positive definiteness\n",
    "    eigvals = np.linalg.eigvalsh(H[t])\n",
    "    if np.min(eigvals) <= 0:\n",
    "        H[t] = H[t] - np.min(eigvals) * np.eye(n) + 0.0001 * np.eye(n)\n",
    "\n",
    "print(\"\\nVECH Model Results with MLE:\")\n",
    "print(\"Last few conditional covariance matrices:\")\n",
    "for t in range(T-5, T):\n",
    "    print(f\"Time {t}:\")\n",
    "    print(H[t])\n",
    "\n",
    "# Generate conditional volatility forecasts\n",
    "forecast_horizon = 5\n",
    "H_forecast = np.zeros((forecast_horizon, n, n))\n",
    "H_forecast[0] = H[-1]\n",
    "\n",
    "for h in range(1, forecast_horizon):\n",
    "    H_forecast[h] = C_opt + B_opt * H_forecast[h-1]\n",
    "\n",
    "print(\"\\nForecasted Covariance Matrices:\")\n",
    "for h in range(forecast_horizon):\n",
    "    print(f\"Horizon {h+1}:\")\n",
    "    print(H_forecast[h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a71d4d69-0785-4bde-b228-bf48e0197742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GARCH Model for returns:\n",
      "                     Constant Mean - GARCH Model Results                      \n",
      "==============================================================================\n",
      "Dep. Variable:                returns   R-squared:                       0.000\n",
      "Mean Model:             Constant Mean   Adj. R-squared:                  0.000\n",
      "Vol Model:                      GARCH   Log-Likelihood:               -53.8088\n",
      "Distribution:                  Normal   AIC:                           115.618\n",
      "Method:            Maximum Likelihood   BIC:                           125.341\n",
      "                                        No. Observations:                   84\n",
      "Date:                Tue, Jun 10 2025   Df Residuals:                       83\n",
      "Time:                        16:43:12   Df Model:                            1\n",
      "==============================================================================\n",
      "\n",
      "GARCH Model for returns2:\n",
      "                     Constant Mean - GARCH Model Results                      \n",
      "==============================================================================\n",
      "Dep. Variable:               returns2   R-squared:                       0.000\n",
      "Mean Model:             Constant Mean   Adj. R-squared:                  0.000\n",
      "Vol Model:                      GARCH   Log-Likelihood:               -39.4859\n",
      "Distribution:                  Normal   AIC:                           86.9718\n",
      "Method:            Maximum Likelihood   BIC:                           96.6951\n",
      "                                        No. Observations:                   84\n",
      "Date:                Tue, Jun 10 2025   Df Residuals:                       83\n",
      "Time:                        16:43:12   Df Model:                            1\n",
      "==============================================================================\n",
      "\n",
      "Unconditional Correlation Matrix:\n",
      "[[1.         0.85436118]\n",
      " [0.85436118 1.        ]]\n",
      "\n",
      "Optimized Parameters:\n",
      "A (ARCH effects):\n",
      "[[0.8388581  0.        ]\n",
      " [0.         0.89841683]]\n",
      "B (GARCH effects):\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "C (Constant term):\n",
      "[[0.1611419  0.08678872]\n",
      " [0.13767338 0.10158317]]\n",
      "\n",
      "Diagonalized VECH Model Results with MLE:\n",
      "Last few conditional covariance matrices:\n",
      "Time 79:\n",
      "[[0.16793313 0.08678872]\n",
      " [0.13767338 0.14040519]]\n",
      "Time 80:\n",
      "[[0.19778981 0.08678872]\n",
      " [0.13767338 0.10284548]]\n",
      "Time 81:\n",
      "[[0.19469622 0.08678872]\n",
      " [0.13767338 0.13234663]]\n",
      "Time 82:\n",
      "[[0.18119934 0.08678872]\n",
      " [0.13767338 0.10476056]]\n",
      "Time 83:\n",
      "[[0.16855641 0.08678872]\n",
      " [0.13767338 0.11261551]]\n",
      "\n",
      "Forecasted Covariance Matrices:\n",
      "Horizon 1:\n",
      "[[0.16855641 0.08678872]\n",
      " [0.13767338 0.11261551]]\n",
      "Horizon 2:\n",
      "[[0.1611419  0.08678872]\n",
      " [0.13767338 0.10158317]]\n",
      "Horizon 3:\n",
      "[[0.1611419  0.08678872]\n",
      " [0.13767338 0.10158317]]\n",
      "Horizon 4:\n",
      "[[0.1611419  0.08678872]\n",
      " [0.13767338 0.10158317]]\n",
      "Horizon 5:\n",
      "[[0.1611419  0.08678872]\n",
      " [0.13767338 0.10158317]]\n"
     ]
    }
   ],
   "source": [
    "##Diagonal VECh Model\n",
    "\n",
    "# Preparing the data\n",
    "# Calculate percentage changes (returns) for the variables\n",
    "data['returns'] = data['price'].pct_change().dropna()\n",
    "data['returns2'] = data['assess'].pct_change().dropna()\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Prepare the returns data for multivariate GARCH\n",
    "returns = data[['returns', 'returns2']]\n",
    "\n",
    "# Number of assets\n",
    "n = returns.shape[1]\n",
    "\n",
    "# Step 1: Estimate univariate GARCH models for each return series\n",
    "garch_models = []\n",
    "for i in range(n):\n",
    "    model = arch_model(returns.iloc[:, i], vol='GARCH', p=1, q=1)\n",
    "    result = model.fit(disp='off')\n",
    "    garch_models.append(result)\n",
    "    print(f\"\\nGARCH Model for {returns.columns[i]}:\")\n",
    "    print(result.summary().tables[0])\n",
    "\n",
    "# Step 2: Implement the diagonalized VECH model using MLE\n",
    "\n",
    "# Compute unconditional correlation matrix\n",
    "corr_const = np.corrcoef(returns.values.T)\n",
    "print(\"\\nUnconditional Correlation Matrix:\")\n",
    "print(corr_const)\n",
    "\n",
    "# Define the negative log-likelihood function\n",
    "def negative_log_likelihood(params, returns_array, corr_const):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood function for the diagonalized VECH model.\n",
    "    \"\"\"\n",
    "    T, n = returns_array.shape\n",
    "    A = np.diag(params[:n])  # Diagonal ARCH effects\n",
    "    B = np.diag(params[n:2*n])  # Diagonal GARCH effects\n",
    "    C = (1 - np.diag(A) - np.diag(B)) * corr_const  # Diagonal constant term\n",
    "\n",
    "    H = np.zeros((T, n, n))  # Conditional covariance matrices\n",
    "    H[0] = corr_const.copy()\n",
    "\n",
    "    log_likelihood = 0\n",
    "    for t in range(1, T):\n",
    "        eps_t = returns_array[t-1].reshape(-1, 1)\n",
    "        eps_eps_t = np.dot(eps_t, eps_t.T)  # Cross-product of residuals\n",
    "\n",
    "        # Diagonalized VECH recursion\n",
    "        H[t] = C + A * eps_eps_t + B * H[t-1]\n",
    "\n",
    "        # Ensure positive definiteness\n",
    "        eigvals = np.linalg.eigvalsh(H[t])\n",
    "        if np.min(eigvals) <= 0:\n",
    "            H[t] = H[t] - np.min(eigvals) * np.eye(n) + 0.0001 * np.eye(n)\n",
    "\n",
    "        # Compute log-likelihood\n",
    "        inv_H_t = np.linalg.inv(H[t])\n",
    "        det_H_t = np.linalg.det(H[t])\n",
    "        log_likelihood += -0.5 * (np.log(det_H_t) + np.dot(returns_array[t], np.dot(inv_H_t, returns_array[t])))\n",
    "\n",
    "    return -log_likelihood  # Return negative log-likelihood for minimization\n",
    "\n",
    "# Initial parameter guesses\n",
    "n_params = 2 * n  # Number of parameters (A and B, diagonal elements only)\n",
    "initial_params = np.random.rand(n_params) * 0.1  # Small random values\n",
    "\n",
    "# Optimize the likelihood function\n",
    "result = minimize(\n",
    "    negative_log_likelihood,\n",
    "    initial_params,\n",
    "    args=(returns.values, corr_const),\n",
    "    method='L-BFGS-B',  # Use a constrained optimization method\n",
    "    bounds=[(0, 1)] * n_params  # Ensure parameters are between 0 and 1\n",
    ")\n",
    "\n",
    "# Extract optimized parameters\n",
    "optimized_params = result.x\n",
    "A_opt = np.diag(optimized_params[:n])  # Diagonal ARCH effects\n",
    "B_opt = np.diag(optimized_params[n:2*n])  # Diagonal GARCH effects\n",
    "C_opt = (1 - np.diag(A_opt) - np.diag(B_opt)) * corr_const  # Diagonal constant term\n",
    "\n",
    "print(\"\\nOptimized Parameters:\")\n",
    "print(\"A (ARCH effects):\")\n",
    "print(A_opt)\n",
    "print(\"B (GARCH effects):\")\n",
    "print(B_opt)\n",
    "print(\"C (Constant term):\")\n",
    "print(C_opt)\n",
    "\n",
    "# Step 3: Estimate the diagonalized VECH model with optimized parameters\n",
    "T = returns.shape[0]  # Ensure T is correctly calculated\n",
    "H = np.zeros((T, n, n))  # Conditional covariance matrices\n",
    "H[0] = corr_const.copy()\n",
    "\n",
    "for t in range(1, T):\n",
    "    eps_t = returns.values[t-1].reshape(-1, 1)  # Access t-1, which is valid\n",
    "    eps_eps_t = np.dot(eps_t, eps_t.T)  # Cross-product of residuals\n",
    "\n",
    "    # Diagonalized VECH recursion with optimized parameters\n",
    "    H[t] = C_opt + A_opt * eps_eps_t + B_opt * H[t-1]\n",
    "\n",
    "    # Ensure positive definiteness\n",
    "    eigvals = np.linalg.eigvalsh(H[t])\n",
    "    if np.min(eigvals) <= 0:\n",
    "        H[t] = H[t] - np.min(eigvals) * np.eye(n) + 0.0001 * np.eye(n)\n",
    "\n",
    "print(\"\\nDiagonalized VECH Model Results with MLE:\")\n",
    "print(\"Last few conditional covariance matrices:\")\n",
    "for t in range(T-5, T):\n",
    "    print(f\"Time {t}:\")\n",
    "    print(H[t])\n",
    "\n",
    "# Generate conditional volatility forecasts\n",
    "forecast_horizon = 5\n",
    "H_forecast = np.zeros((forecast_horizon, n, n))\n",
    "H_forecast[0] = H[-1]\n",
    "\n",
    "for h in range(1, forecast_horizon):\n",
    "    H_forecast[h] = C_opt + B_opt * H_forecast[h-1]\n",
    "\n",
    "print(\"\\nForecasted Covariance Matrices:\")\n",
    "for h in range(forecast_horizon):\n",
    "    print(f\"Horizon {h+1}:\")\n",
    "    print(H_forecast[h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20657a10-a3a3-4cd2-a17d-3dc515e1decd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GARCH Model for returns:\n",
      "                     Constant Mean - GARCH Model Results                      \n",
      "==============================================================================\n",
      "Dep. Variable:                returns   R-squared:                       0.000\n",
      "Mean Model:             Constant Mean   Adj. R-squared:                  0.000\n",
      "Vol Model:                      GARCH   Log-Likelihood:               -50.6922\n",
      "Distribution:                  Normal   AIC:                           109.384\n",
      "Method:            Maximum Likelihood   BIC:                           119.060\n",
      "                                        No. Observations:                   83\n",
      "Date:                Tue, Jun 10 2025   Df Residuals:                       82\n",
      "Time:                        16:43:14   Df Model:                            1\n",
      "==============================================================================\n",
      "\n",
      "GARCH Model for returns2:\n",
      "                     Constant Mean - GARCH Model Results                      \n",
      "==============================================================================\n",
      "Dep. Variable:               returns2   R-squared:                       0.000\n",
      "Mean Model:             Constant Mean   Adj. R-squared:                  0.000\n",
      "Vol Model:                      GARCH   Log-Likelihood:               -39.1185\n",
      "Distribution:                  Normal   AIC:                           86.2371\n",
      "Method:            Maximum Likelihood   BIC:                           95.9124\n",
      "                                        No. Observations:                   83\n",
      "Date:                Tue, Jun 10 2025   Df Residuals:                       82\n",
      "Time:                        16:43:14   Df Model:                            1\n",
      "==============================================================================\n",
      "\n",
      "Unconditional Correlation Matrix:\n",
      "[[1.         0.85704347]\n",
      " [0.85704347 1.        ]]\n",
      "\n",
      "Optimized Parameters:\n",
      "A (ARCH effects):\n",
      "[[0.83848586 0.        ]\n",
      " [0.         0.89740236]]\n",
      "B (GARCH effects):\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "C (Constant term):\n",
      "[[0.16151414 0.08793064]\n",
      " [0.13842464 0.10259764]]\n",
      "\n",
      "Diagonalized VECH Model Results with MLE:\n",
      "Last few conditional covariance matrices:\n",
      "Time 78:\n",
      "[[0.16830236 0.08793064]\n",
      " [0.13842464 0.14137582]]\n",
      "Time 79:\n",
      "[[0.19814578 0.08793064]\n",
      " [0.13842464 0.10385851]]\n",
      "Time 80:\n",
      "[[0.19505357 0.08793064]\n",
      " [0.13842464 0.13332636]]\n",
      "Time 81:\n",
      "[[0.1815124  0.08793064]\n",
      " [0.13842464 0.10572332]]\n",
      "Time 82:\n",
      "[[0.16891307 0.08793064]\n",
      " [0.13842464 0.1136065 ]]\n",
      "\n",
      "Forecasted Covariance Matrices:\n",
      "Horizon 1:\n",
      "[[0.16891307 0.08793064]\n",
      " [0.13842464 0.1136065 ]]\n",
      "Horizon 2:\n",
      "[[0.16151414 0.08793064]\n",
      " [0.13842464 0.10259764]]\n",
      "Horizon 3:\n",
      "[[0.16151414 0.08793064]\n",
      " [0.13842464 0.10259764]]\n",
      "Horizon 4:\n",
      "[[0.16151414 0.08793064]\n",
      " [0.13842464 0.10259764]]\n",
      "Horizon 5:\n",
      "[[0.16151414 0.08793064]\n",
      " [0.13842464 0.10259764]]\n"
     ]
    }
   ],
   "source": [
    "##BEKK model\n",
    "\n",
    "# Preparing the data\n",
    "# Calculate percentage changes (returns) for the variables\n",
    "data['returns'] = data['price'].pct_change().dropna()\n",
    "data['returns2'] = data['assess'].pct_change().dropna()\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Prepare the returns data for multivariate GARCH\n",
    "returns = data[['returns', 'returns2']]\n",
    "\n",
    "# Number of assets\n",
    "n = returns.shape[1]\n",
    "\n",
    "# Step 1: Estimate univariate GARCH models for each return series\n",
    "garch_models = []\n",
    "for i in range(n):\n",
    "    model = arch_model(returns.iloc[:, i], vol='GARCH', p=1, q=1)\n",
    "    result = model.fit(disp='off')\n",
    "    garch_models.append(result)\n",
    "    print(f\"\\nGARCH Model for {returns.columns[i]}:\")\n",
    "    print(result.summary().tables[0])\n",
    "\n",
    "# Step 2: Compute unconditional correlation matrix\n",
    "corr_const = np.corrcoef(returns.values.T)\n",
    "print(\"\\nUnconditional Correlation Matrix:\")\n",
    "print(corr_const)\n",
    "\n",
    "# Step 3: Define the negative log-likelihood function for diagonalized VECH\n",
    "def negative_log_likelihood(params, returns_array, corr_const):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood function for the diagonalized VECH model.\n",
    "    \"\"\"\n",
    "    T, n = returns_array.shape\n",
    "    A = np.diag(params[:n])  # Diagonal ARCH effects\n",
    "    B = np.diag(params[n:2*n])  # Diagonal GARCH effects\n",
    "    C = (1 - np.diag(A) - np.diag(B)) * corr_const  # Diagonal constant term\n",
    "\n",
    "    H = np.zeros((T, n, n))  # Conditional covariance matrices\n",
    "    H[0] = corr_const.copy()\n",
    "\n",
    "    log_likelihood = 0\n",
    "    for t in range(1, T):\n",
    "        eps_t = returns_array[t-1].reshape(-1, 1)\n",
    "        eps_eps_t = np.dot(eps_t, eps_t.T)  # Cross-product of residuals\n",
    "\n",
    "        # Diagonalized VECH recursion\n",
    "        H[t] = C + A * eps_eps_t + B * H[t-1]\n",
    "\n",
    "        # Ensure positive definiteness\n",
    "        eigvals = np.linalg.eigvalsh(H[t])\n",
    "        if np.min(eigvals) <= 0:\n",
    "            H[t] = H[t] - np.min(eigvals) * np.eye(n) + 0.0001 * np.eye(n)\n",
    "\n",
    "        # Compute log-likelihood\n",
    "        inv_H_t = np.linalg.inv(H[t])\n",
    "        det_H_t = np.linalg.det(H[t])\n",
    "        log_likelihood += -0.5 * (np.log(det_H_t) + np.dot(returns_array[t], np.dot(inv_H_t, returns_array[t])))\n",
    "\n",
    "    return -log_likelihood  # Return negative log-likelihood for minimization\n",
    "\n",
    "# Step 4: Initial parameter guesses\n",
    "n_params = 2 * n  # Number of parameters (A and B, diagonal elements only)\n",
    "initial_params = np.random.rand(n_params) * 0.1  # Small random values\n",
    "\n",
    "# Step 5: Optimize the likelihood function\n",
    "result = minimize(\n",
    "    negative_log_likelihood,\n",
    "    initial_params,\n",
    "    args=(returns.values, corr_const),\n",
    "    method='L-BFGS-B',  # Use a constrained optimization method\n",
    "    bounds=[(0, 1)] * n_params  # Ensure parameters are between 0 and 1\n",
    ")\n",
    "\n",
    "# Step 6: Extract optimized parameters\n",
    "optimized_params = result.x\n",
    "A_opt = np.diag(optimized_params[:n])  # Diagonal ARCH effects\n",
    "B_opt = np.diag(optimized_params[n:2*n])  # Diagonal GARCH effects\n",
    "C_opt = (1 - np.diag(A_opt) - np.diag(B_opt)) * corr_const  # Diagonal constant term\n",
    "\n",
    "# Step 7: Print optimized parameters\n",
    "print(\"\\nOptimized Parameters:\")\n",
    "print(\"A (ARCH effects):\")\n",
    "print(A_opt)\n",
    "print(\"B (GARCH effects):\")\n",
    "print(B_opt)\n",
    "print(\"C (Constant term):\")\n",
    "print(C_opt)\n",
    "\n",
    "# Step 8: Estimate the diagonalized VECH model with optimized parameters\n",
    "T = returns.shape[0]\n",
    "H = np.zeros((T, n, n))\n",
    "H[0] = corr_const.copy()\n",
    "\n",
    "for t in range(1, T):\n",
    "    eps_t = returns.values[t-1].reshape(-1, 1)\n",
    "    eps_eps_t = np.dot(eps_t, eps_t.T)\n",
    "\n",
    "    # Diagonalized VECH recursion with optimized parameters\n",
    "    H[t] = C_opt + A_opt * eps_eps_t + B_opt * H[t-1]\n",
    "\n",
    "    # Ensure positive definiteness\n",
    "    eigvals = np.linalg.eigvalsh(H[t])\n",
    "    if np.min(eigvals) <= 0:\n",
    "        H[t] = H[t] - np.min(eigvals) * np.eye(n) + 0.0001 * np.eye(n)\n",
    "\n",
    "# Step 9: Print conditional covariance matrices\n",
    "print(\"\\nDiagonalized VECH Model Results with MLE:\")\n",
    "print(\"Last few conditional covariance matrices:\")\n",
    "for t in range(T-5, T):\n",
    "    print(f\"Time {t}:\")\n",
    "    print(H[t])\n",
    "\n",
    "# Step 10: Generate conditional volatility forecasts\n",
    "forecast_horizon = 5\n",
    "H_forecast = np.zeros((forecast_horizon, n, n))\n",
    "H_forecast[0] = H[-1]\n",
    "\n",
    "for h in range(1, forecast_horizon):\n",
    "    H_forecast[h] = C_opt + B_opt * H_forecast[h-1]\n",
    "\n",
    "# Step 11: Print forecasted covariance matrices\n",
    "print(\"\\nForecasted Covariance Matrices:\")\n",
    "for h in range(forecast_horizon):\n",
    "    print(f\"Horizon {h+1}:\")\n",
    "    print(H_forecast[h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "927796c1-2749-45c0-8436-d03b432c751c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GARCH Model for returns:\n",
      "                     Constant Mean - GARCH Model Results                      \n",
      "==============================================================================\n",
      "Dep. Variable:                returns   R-squared:                       0.000\n",
      "Mean Model:             Constant Mean   Adj. R-squared:                  0.000\n",
      "Vol Model:                      GARCH   Log-Likelihood:               -50.7591\n",
      "Distribution:                  Normal   AIC:                           109.518\n",
      "Method:            Maximum Likelihood   BIC:                           119.145\n",
      "                                        No. Observations:                   82\n",
      "Date:                Tue, Jun 10 2025   Df Residuals:                       81\n",
      "Time:                        16:43:15   Df Model:                            1\n",
      "==============================================================================\n",
      "\n",
      "GARCH Model for returns2:\n",
      "                     Constant Mean - GARCH Model Results                      \n",
      "==============================================================================\n",
      "Dep. Variable:               returns2   R-squared:                       0.000\n",
      "Mean Model:             Constant Mean   Adj. R-squared:                  0.000\n",
      "Vol Model:                      GARCH   Log-Likelihood:               -39.0391\n",
      "Distribution:                  Normal   AIC:                           86.0781\n",
      "Method:            Maximum Likelihood   BIC:                           95.7050\n",
      "                                        No. Observations:                   82\n",
      "Date:                Tue, Jun 10 2025   Df Residuals:                       81\n",
      "Time:                        16:43:15   Df Model:                            1\n",
      "==============================================================================\n",
      "\n",
      "Constant Conditional Correlation Matrix:\n",
      "[[1.         0.86097376]\n",
      " [0.86097376 1.        ]]\n",
      "\n",
      "CCC Model Results:\n",
      "Last few conditional covariance matrices:\n",
      "Time 77:\n",
      "[[0.30587739 0.21562937]\n",
      " [0.21562937 0.20506362]]\n",
      "Time 78:\n",
      "[[0.30802919 0.21669504]\n",
      " [0.21669504 0.20564882]]\n",
      "Time 79:\n",
      "[[0.31017587 0.2177517 ]\n",
      " [0.2177517  0.20622213]]\n",
      "Time 80:\n",
      "[[0.31231744 0.21879948]\n",
      " [0.21879948 0.2067838 ]]\n",
      "Time 81:\n",
      "[[0.31445391 0.21983849]\n",
      " [0.21983849 0.20733406]]\n",
      "\n",
      "Forecasted Covariance Matrices (CCC Model):\n",
      "Horizon 1:\n",
      "[[0.31579196 0.22055056]\n",
      " [0.22055056 0.20779516]]\n",
      "Horizon 2:\n",
      "[[0.31792016 0.22157436]\n",
      " [0.22157436 0.20832487]]\n",
      "Horizon 3:\n",
      "[[0.3200433  0.22258972]\n",
      " [0.22258972 0.20884382]]\n",
      "Horizon 4:\n",
      "[[0.32216138 0.22359673]\n",
      " [0.22359673 0.20935224]]\n",
      "Horizon 5:\n",
      "[[0.32427442 0.22459551]\n",
      " [0.22459551 0.20985032]]\n"
     ]
    }
   ],
   "source": [
    "##CCC Model\n",
    "\n",
    "# Assuming 'data' is a DataFrame with columns 'price' and 'assess'\n",
    "# Calculate percentage changes (returns) for the variables\n",
    "data['returns'] = data['price'].pct_change().dropna()\n",
    "data['returns2'] = data['assess'].pct_change().dropna()\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Prepare the returns data for multivariate GARCH\n",
    "returns = data[['returns', 'returns2']]\n",
    "\n",
    "# Number of assets\n",
    "n = returns.shape[1]\n",
    "\n",
    "# Step 1: Estimate univariate GARCH models for each return series\n",
    "garch_models = []\n",
    "for i in range(n):\n",
    "    model = arch_model(returns.iloc[:, i], vol='GARCH', p=1, q=1)\n",
    "    result = model.fit(disp='off')\n",
    "    garch_models.append(result)\n",
    "    print(f\"\\nGARCH Model for {returns.columns[i]}:\")\n",
    "    print(result.summary().tables[0])\n",
    "\n",
    "# Step 2: Extract conditional variances from univariate GARCH models\n",
    "conditional_variances = np.zeros_like(returns.values)\n",
    "for i in range(n):\n",
    "    conditional_variances[:, i] = garch_models[i].conditional_volatility**2\n",
    "\n",
    "# Step 3: Standardize the returns using conditional volatilities\n",
    "standardized_returns = returns.values / np.sqrt(conditional_variances)\n",
    "\n",
    "# Step 4: Compute the constant conditional correlation matrix\n",
    "corr_ccc = np.corrcoef(standardized_returns.T)\n",
    "print(\"\\nConstant Conditional Correlation Matrix:\")\n",
    "print(corr_ccc)\n",
    "\n",
    "# Step 5: Construct conditional covariance matrices\n",
    "T = returns.shape[0]\n",
    "H_ccc = np.zeros((T, n, n))\n",
    "\n",
    "for t in range(T):\n",
    "    D_t = np.diag(np.sqrt(conditional_variances[t]))  # Diagonal matrix of conditional standard deviations\n",
    "    H_ccc[t] = D_t @ corr_ccc @ D_t  # Construct conditional covariance matrix\n",
    "\n",
    "# Step 6: Print conditional covariance matrices\n",
    "print(\"\\nCCC Model Results:\")\n",
    "print(\"Last few conditional covariance matrices:\")\n",
    "for t in range(T-5, T):\n",
    "    print(f\"Time {t}:\")\n",
    "    print(H_ccc[t])\n",
    "\n",
    "# Step 7: Forecast conditional variances\n",
    "forecast_horizon = 5\n",
    "conditional_variance_forecasts = np.zeros((forecast_horizon, n))\n",
    "\n",
    "for i in range(n):\n",
    "    forecasts = garch_models[i].forecast(horizon=forecast_horizon, reindex=False).variance.values[-1]\n",
    "    conditional_variance_forecasts[:, i] = forecasts\n",
    "\n",
    "# Step 8: Construct forecasted conditional covariance matrices\n",
    "H_ccc_forecast = np.zeros((forecast_horizon, n, n))\n",
    "\n",
    "for h in range(forecast_horizon):\n",
    "    D_t = np.diag(np.sqrt(conditional_variance_forecasts[h]))  # Diagonal matrix of forecasted conditional standard deviations\n",
    "    H_ccc_forecast[h] = D_t @ corr_ccc @ D_t  # Construct forecasted conditional covariance matrix\n",
    "\n",
    "# Step 9: Print forecasted covariance matrices\n",
    "print(\"\\nForecasted Covariance Matrices (CCC Model):\")\n",
    "for h in range(forecast_horizon):\n",
    "    print(f\"Horizon {h+1}:\")\n",
    "    print(H_ccc_forecast[h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11386f92-3ad4-4093-bc74-dd21682641d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
